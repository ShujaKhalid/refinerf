[1mdiff --git a/Umbrella/log_ngp.txt b/Umbrella/log_ngp.txt[m
[1mindex 6793a16..94dd57e 100644[m
[1m--- a/Umbrella/log_ngp.txt[m
[1m+++ b/Umbrella/log_ngp.txt[m
[36m@@ -1,71 +1,56 @@[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-49-19 | cuda | fp16 | Umbrella[m
[32m+[m[32m[INFO] Trainer: ngp | 2022-08-13_21-14-28 | cuda | fp16 | Umbrella[m
 [INFO] #parameters: 12866535[m
 [INFO] Loading latest checkpoint ...[m
 [WARN] No checkpoint found, model randomly initialized.[m
 ==> Start Training Epoch 1, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-49-46 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12829671[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[WARN] No checkpoint found, model randomly initialized.[m
[31m-==> Start Training Epoch 1, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-50-23 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12829671[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[WARN] No checkpoint found, model randomly initialized.[m
[31m-==> Start Training Epoch 1, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-54-26 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[WARN] No checkpoint found, model randomly initialized.[m
[31m-==> Start Training Epoch 1, lr=0.010000 ...[m
 ==> Finished Epoch 1.[m
[31m-==> Start Training Epoch 2, lr=0.009988 ...[m
[32m+[m[32m==> Start Training Epoch 2, lr=0.010000 ...[m
 ==> Finished Epoch 2.[m
[31m-==> Start Training Epoch 3, lr=0.009977 ...[m
[32m+[m[32m==> Start Training Epoch 3, lr=0.010000 ...[m
 ==> Finished Epoch 3.[m
[31m-==> Start Training Epoch 4, lr=0.009966 ...[m
[32m+[m[32m==> Start Training Epoch 4, lr=0.010000 ...[m
 ==> Finished Epoch 4.[m
[31m-==> Start Training Epoch 5, lr=0.009954 ...[m
[32m+[m[32m==> Start Training Epoch 5, lr=0.010000 ...[m
 ==> Finished Epoch 5.[m
[31m-==> Start Training Epoch 6, lr=0.009943 ...[m
[32m+[m[32m==> Start Training Epoch 6, lr=0.010000 ...[m
 ==> Finished Epoch 6.[m
[31m-==> Start Training Epoch 7, lr=0.009931 ...[m
[32m+[m[32m==> Start Training Epoch 7, lr=0.010000 ...[m
 ==> Finished Epoch 7.[m
[31m-==> Start Training Epoch 8, lr=0.009920 ...[m
[32m+[m[32m==> Start Training Epoch 8, lr=0.010000 ...[m
 ==> Finished Epoch 8.[m
[31m-==> Start Training Epoch 9, lr=0.009908 ...[m
[32m+[m[32m==> Start Training Epoch 9, lr=0.010000 ...[m
 ==> Finished Epoch 9.[m
[31m-==> Start Training Epoch 10, lr=0.009897 ...[m
[32m+[m[32m==> Start Training Epoch 10, lr=0.010000 ...[m
 ==> Finished Epoch 10.[m
 ++> Evaluate at epoch 10 ...[m
[31m-PSNR = 18.935864 - SSIM = 0.000000 - LPIPS = 0.000000[m
[32m+[m[32mPSNR = 15.016976 - SSIM = 0.000000 - LPIPS = 0.000000[m
 ++> Evaluate epoch 10 Finished.[m
[31m-[INFO] New best result: None --> 0.012788699474185705[m
[31m-==> Start Training Epoch 11, lr=0.009886 ...[m
[32m+[m[32m[INFO] New best result: None --> 0.0315051362849772[m
[32m+[m[32m==> Start Training Epoch 11, lr=0.010000 ...[m
 ==> Finished Epoch 11.[m
[31m-==> Start Training Epoch 12, lr=0.009874 ...[m
[32m+[m[32m==> Start Training Epoch 12, lr=0.010000 ...[m
 ==> Finished Epoch 12.[m
[31m-==> Start Training Epoch 13, lr=0.009863 ...[m
[32m+[m[32m==> Start Training Epoch 13, lr=0.010000 ...[m
 ==> Finished Epoch 13.[m
[31m-==> Start Training Epoch 14, lr=0.009851 ...[m
[32m+[m[32m==> Start Training Epoch 14, lr=0.010000 ...[m
 ==> Finished Epoch 14.[m
[31m-==> Start Training Epoch 15, lr=0.009840 ...[m
[32m+[m[32m==> Start Training Epoch 15, lr=0.010000 ...[m
 ==> Finished Epoch 15.[m
[31m-==> Start Training Epoch 16, lr=0.009829 ...[m
[32m+[m[32m==> Start Training Epoch 16, lr=0.010000 ...[m
 ==> Finished Epoch 16.[m
[31m-==> Start Training Epoch 17, lr=0.009817 ...[m
[32m+[m[32m==> Start Training Epoch 17, lr=0.010000 ...[m
 ==> Finished Epoch 17.[m
[31m-==> Start Training Epoch 18, lr=0.009806 ...[m
[32m+[m[32m==> Start Training Epoch 18, lr=0.010000 ...[m
 ==> Finished Epoch 18.[m
[31m-==> Start Training Epoch 19, lr=0.009795 ...[m
[32m+[m[32m==> Start Training Epoch 19, lr=0.010000 ...[m
 ==> Finished Epoch 19.[m
[31m-==> Start Training Epoch 20, lr=0.009784 ...[m
[32m+[m[32m==> Start Training Epoch 20, lr=0.010000 ...[m
 ==> Finished Epoch 20.[m
 ++> Evaluate at epoch 20 ...[m
[31m-PSNR = 19.477971 - SSIM = 0.000000 - LPIPS = 0.000000[m
[32m+[m[32mPSNR = 15.099158 - SSIM = 0.000000 - LPIPS = 0.000000[m
 ++> Evaluate epoch 20 Finished.[m
[31m-[INFO] New best result: 0.012788699474185705 --> 0.011294273737197122[m
[31m-==> Start Training Epoch 21, lr=0.009772 ...[m
[32m+[m[32m[INFO] New best result: 0.0315051362849772 --> 0.030918311793357134[m
[32m+[m[32m==> Start Training Epoch 21, lr=0.010000 ...[m
 ==> Finished Epoch 21.[m
 ==> Start Training Epoch 22, lr=0.010000 ...[m
 ==> Finished Epoch 22.[m
[36m@@ -86,514 +71,10 @@[m [mPSNR = 19.477971 - SSIM = 0.000000 - LPIPS = 0.000000[m
 ==> Start Training Epoch 30, lr=0.010000 ...[m
 ==> Finished Epoch 30.[m
 ++> Evaluate at epoch 30 ...[m
[31m-PSNR = 20.803572 - SSIM = 0.000000 - LPIPS = 0.000000[m
[32m+[m[32mPSNR = 15.035914 - SSIM = 0.000000 - LPIPS = 0.000000[m
 ++> Evaluate epoch 30 Finished.[m
[31m-[INFO] New best result: 0.011294273737197122 --> 0.008378526661545038[m
 ==> Start Training Epoch 31, lr=0.010000 ...[m
 ==> Finished Epoch 31.[m
 ==> Start Training Epoch 32, lr=0.010000 ...[m
 ==> Finished Epoch 32.[m
 ==> Start Training Epoch 33, lr=0.010000 ...[m
[31m-==> Finished Epoch 33.[m
[31m-==> Start Training Epoch 34, lr=0.010000 ...[m
[31m-==> Finished Epoch 34.[m
[31m-==> Start Training Epoch 35, lr=0.010000 ...[m
[31m-==> Finished Epoch 35.[m
[31m-==> Start Training Epoch 36, lr=0.010000 ...[m
[31m-==> Finished Epoch 36.[m
[31m-==> Start Training Epoch 37, lr=0.010000 ...[m
[31m-==> Finished Epoch 37.[m
[31m-==> Start Training Epoch 38, lr=0.010000 ...[m
[31m-==> Finished Epoch 38.[m
[31m-==> Start Training Epoch 39, lr=0.010000 ...[m
[31m-==> Finished Epoch 39.[m
[31m-==> Start Training Epoch 40, lr=0.010000 ...[m
[31m-==> Finished Epoch 40.[m
[31m-++> Evaluate at epoch 40 ...[m
[31m-PSNR = 20.768385 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 40 Finished.[m
[31m-==> Start Training Epoch 41, lr=0.010000 ...[m
[31m-==> Finished Epoch 41.[m
[31m-==> Start Training Epoch 42, lr=0.010000 ...[m
[31m-==> Finished Epoch 42.[m
[31m-==> Start Training Epoch 43, lr=0.010000 ...[m
[31m-==> Finished Epoch 43.[m
[31m-==> Start Training Epoch 44, lr=0.010000 ...[m
[31m-==> Finished Epoch 44.[m
[31m-==> Start Training Epoch 45, lr=0.010000 ...[m
[31m-==> Finished Epoch 45.[m
[31m-==> Start Training Epoch 46, lr=0.010000 ...[m
[31m-==> Finished Epoch 46.[m
[31m-==> Start Training Epoch 47, lr=0.010000 ...[m
[31m-==> Finished Epoch 47.[m
[31m-==> Start Training Epoch 48, lr=0.010000 ...[m
[31m-==> Finished Epoch 48.[m
[31m-==> Start Training Epoch 49, lr=0.010000 ...[m
[31m-==> Finished Epoch 49.[m
[31m-==> Start Training Epoch 50, lr=0.010000 ...[m
[31m-==> Finished Epoch 50.[m
[31m-++> Evaluate at epoch 50 ...[m
[31m-PSNR = 20.331226 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 50 Finished.[m
[31m-==> Start Training Epoch 51, lr=0.010000 ...[m
[31m-==> Finished Epoch 51.[m
[31m-==> Start Training Epoch 52, lr=0.010000 ...[m
[31m-==> Finished Epoch 52.[m
[31m-==> Start Training Epoch 53, lr=0.010000 ...[m
[31m-==> Finished Epoch 53.[m
[31m-==> Start Training Epoch 54, lr=0.010000 ...[m
[31m-==> Finished Epoch 54.[m
[31m-==> Start Training Epoch 55, lr=0.010000 ...[m
[31m-==> Finished Epoch 55.[m
[31m-==> Start Training Epoch 56, lr=0.010000 ...[m
[31m-==> Finished Epoch 56.[m
[31m-==> Start Training Epoch 57, lr=0.010000 ...[m
[31m-==> Finished Epoch 57.[m
[31m-==> Start Training Epoch 58, lr=0.010000 ...[m
[31m-==> Finished Epoch 58.[m
[31m-==> Start Training Epoch 59, lr=0.010000 ...[m
[31m-==> Finished Epoch 59.[m
[31m-==> Start Training Epoch 60, lr=0.010000 ...[m
[31m-==> Finished Epoch 60.[m
[31m-++> Evaluate at epoch 60 ...[m
[31m-PSNR = 19.972837 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 60 Finished.[m
[31m-==> Start Training Epoch 61, lr=0.010000 ...[m
[31m-==> Finished Epoch 61.[m
[31m-==> Start Training Epoch 62, lr=0.010000 ...[m
[31m-==> Finished Epoch 62.[m
[31m-==> Start Training Epoch 63, lr=0.010000 ...[m
[31m-==> Finished Epoch 63.[m
[31m-==> Start Training Epoch 64, lr=0.010000 ...[m
[31m-==> Finished Epoch 64.[m
[31m-==> Start Training Epoch 65, lr=0.010000 ...[m
[31m-==> Finished Epoch 65.[m
[31m-==> Start Training Epoch 66, lr=0.010000 ...[m
[31m-==> Finished Epoch 66.[m
[31m-==> Start Training Epoch 67, lr=0.010000 ...[m
[31m-==> Finished Epoch 67.[m
[31m-==> Start Training Epoch 68, lr=0.010000 ...[m
[31m-==> Finished Epoch 68.[m
[31m-==> Start Training Epoch 69, lr=0.010000 ...[m
[31m-==> Finished Epoch 69.[m
[31m-==> Start Training Epoch 70, lr=0.010000 ...[m
[31m-==> Finished Epoch 70.[m
[31m-++> Evaluate at epoch 70 ...[m
[31m-PSNR = 19.794320 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 70 Finished.[m
[31m-==> Start Training Epoch 71, lr=0.010000 ...[m
[31m-==> Finished Epoch 71.[m
[31m-==> Start Training Epoch 72, lr=0.010000 ...[m
[31m-==> Finished Epoch 72.[m
[31m-==> Start Training Epoch 73, lr=0.010000 ...[m
[31m-==> Finished Epoch 73.[m
[31m-==> Start Training Epoch 74, lr=0.010000 ...[m
[31m-==> Finished Epoch 74.[m
[31m-==> Start Training Epoch 75, lr=0.010000 ...[m
[31m-==> Finished Epoch 75.[m
[31m-==> Start Training Epoch 76, lr=0.010000 ...[m
[31m-==> Finished Epoch 76.[m
[31m-==> Start Training Epoch 77, lr=0.010000 ...[m
[31m-==> Finished Epoch 77.[m
[31m-==> Start Training Epoch 78, lr=0.010000 ...[m
[31m-==> Finished Epoch 78.[m
[31m-==> Start Training Epoch 79, lr=0.010000 ...[m
[31m-==> Finished Epoch 79.[m
[31m-==> Start Training Epoch 80, lr=0.010000 ...[m
[31m-==> Finished Epoch 80.[m
[31m-++> Evaluate at epoch 80 ...[m
[31m-PSNR = 19.684872 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 80 Finished.[m
[31m-==> Start Training Epoch 81, lr=0.010000 ...[m
[31m-==> Finished Epoch 81.[m
[31m-==> Start Training Epoch 82, lr=0.010000 ...[m
[31m-==> Finished Epoch 82.[m
[31m-==> Start Training Epoch 83, lr=0.010000 ...[m
[31m-==> Finished Epoch 83.[m
[31m-==> Start Training Epoch 84, lr=0.010000 ...[m
[31m-==> Finished Epoch 84.[m
[31m-==> Start Training Epoch 85, lr=0.010000 ...[m
[31m-==> Finished Epoch 85.[m
[31m-==> Start Training Epoch 86, lr=0.010000 ...[m
[31m-==> Finished Epoch 86.[m
[31m-==> Start Training Epoch 87, lr=0.010000 ...[m
[31m-==> Finished Epoch 87.[m
[31m-==> Start Training Epoch 88, lr=0.010000 ...[m
[31m-==> Finished Epoch 88.[m
[31m-==> Start Training Epoch 89, lr=0.010000 ...[m
[31m-==> Finished Epoch 89.[m
[31m-==> Start Training Epoch 90, lr=0.010000 ...[m
[31m-==> Finished Epoch 90.[m
[31m-++> Evaluate at epoch 90 ...[m
[31m-PSNR = 19.621430 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 90 Finished.[m
[31m-==> Start Training Epoch 91, lr=0.010000 ...[m
[31m-==> Finished Epoch 91.[m
[31m-==> Start Training Epoch 92, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_01-07-45 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0091.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 91, global step 1092[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 92, lr=0.010000 ...[m
[31m-==> Finished Epoch 92.[m
[31m-==> Start Training Epoch 93, lr=0.008995 ...[m
[31m-==> Finished Epoch 93.[m
[31m-==> Start Training Epoch 94, lr=0.008985 ...[m
[31m-==> Finished Epoch 94.[m
[31m-==> Start Training Epoch 95, lr=0.008974 ...[m
[31m-==> Finished Epoch 95.[m
[31m-==> Start Training Epoch 96, lr=0.008964 ...[m
[31m-==> Finished Epoch 96.[m
[31m-==> Start Training Epoch 97, lr=0.008954 ...[m
[31m-==> Finished Epoch 97.[m
[31m-==> Start Training Epoch 98, lr=0.008943 ...[m
[31m-==> Finished Epoch 98.[m
[31m-==> Start Training Epoch 99, lr=0.008933 ...[m
[31m-==> Finished Epoch 99.[m
[31m-==> Start Training Epoch 100, lr=0.008923 ...[m
[31m-==> Finished Epoch 100.[m
[31m-++> Evaluate at epoch 100 ...[m
[31m-PSNR = 20.407415 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 100 Finished.[m
[31m-==> Start Training Epoch 101, lr=0.008913 ...[m
[31m-==> Finished Epoch 101.[m
[31m-==> Start Training Epoch 102, lr=0.010000 ...[m
[31m-==> Finished Epoch 102.[m
[31m-==> Start Training Epoch 103, lr=0.010000 ...[m
[31m-==> Finished Epoch 103.[m
[31m-==> Start Training Epoch 104, lr=0.010000 ...[m
[31m-==> Finished Epoch 104.[m
[31m-==> Start Training Epoch 105, lr=0.010000 ...[m
[31m-==> Finished Epoch 105.[m
[31m-==> Start Training Epoch 106, lr=0.010000 ...[m
[31m-==> Finished Epoch 106.[m
[31m-==> Start Training Epoch 107, lr=0.010000 ...[m
[31m-==> Finished Epoch 107.[m
[31m-==> Start Training Epoch 108, lr=0.010000 ...[m
[31m-==> Finished Epoch 108.[m
[31m-==> Start Training Epoch 109, lr=0.010000 ...[m
[31m-==> Finished Epoch 109.[m
[31m-==> Start Training Epoch 110, lr=0.010000 ...[m
[31m-==> Finished Epoch 110.[m
[31m-++> Evaluate at epoch 110 ...[m
[31m-PSNR = 20.834493 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 110 Finished.[m
[31m-==> Start Training Epoch 111, lr=0.010000 ...[m
[31m-==> Finished Epoch 111.[m
[31m-==> Start Training Epoch 112, lr=0.010000 ...[m
[31m-==> Finished Epoch 112.[m
[31m-==> Start Training Epoch 113, lr=0.010000 ...[m
[31m-==> Finished Epoch 113.[m
[31m-==> Start Training Epoch 114, lr=0.010000 ...[m
[31m-==> Finished Epoch 114.[m
[31m-==> Start Training Epoch 115, lr=0.010000 ...[m
[31m-==> Finished Epoch 115.[m
[31m-==> Start Training Epoch 116, lr=0.010000 ...[m
[31m-==> Finished Epoch 116.[m
[31m-==> Start Training Epoch 117, lr=0.010000 ...[m
[31m-==> Finished Epoch 117.[m
[31m-==> Start Training Epoch 118, lr=0.010000 ...[m
[31m-==> Finished Epoch 118.[m
[31m-==> Start Training Epoch 119, lr=0.010000 ...[m
[31m-==> Finished Epoch 119.[m
[31m-==> Start Training Epoch 120, lr=0.010000 ...[m
[31m-==> Finished Epoch 120.[m
[31m-++> Evaluate at epoch 120 ...[m
[31m-PSNR = 21.062913 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 120 Finished.[m
[31m-[INFO] New best result: 0.008378526661545038 --> 0.008318509596089521[m
[31m-==> Start Training Epoch 121, lr=0.010000 ...[m
[31m-==> Finished Epoch 121.[m
[31m-==> Start Training Epoch 122, lr=0.010000 ...[m
[31m-==> Finished Epoch 122.[m
[31m-==> Start Training Epoch 123, lr=0.010000 ...[m
[31m-==> Finished Epoch 123.[m
[31m-==> Start Training Epoch 124, lr=0.010000 ...[m
[31m-==> Finished Epoch 124.[m
[31m-==> Start Training Epoch 125, lr=0.010000 ...[m
[31m-==> Finished Epoch 125.[m
[31m-==> Start Training Epoch 126, lr=0.010000 ...[m
[31m-==> Finished Epoch 126.[m
[31m-==> Start Training Epoch 127, lr=0.010000 ...[m
[31m-==> Finished Epoch 127.[m
[31m-==> Start Training Epoch 128, lr=0.010000 ...[m
[31m-==> Finished Epoch 128.[m
[31m-==> Start Training Epoch 129, lr=0.010000 ...[m
[31m-==> Finished Epoch 129.[m
[31m-==> Start Training Epoch 130, lr=0.010000 ...[m
[31m-==> Finished Epoch 130.[m
[31m-++> Evaluate at epoch 130 ...[m
[31m-PSNR = 21.071117 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 130 Finished.[m
[31m-[INFO] New best result: 0.008318509596089521 --> 0.008297114555413524[m
[31m-==> Start Training Epoch 131, lr=0.010000 ...[m
[31m-==> Finished Epoch 131.[m
[31m-==> Start Training Epoch 132, lr=0.010000 ...[m
[31m-==> Finished Epoch 132.[m
[31m-==> Start Training Epoch 133, lr=0.010000 ...[m
[31m-==> Finished Epoch 133.[m
[31m-==> Start Training Epoch 134, lr=0.010000 ...[m
[31m-==> Finished Epoch 134.[m
[31m-==> Start Training Epoch 135, lr=0.010000 ...[m
[31m-==> Finished Epoch 135.[m
[31m-==> Start Training Epoch 136, lr=0.010000 ...[m
[31m-==> Finished Epoch 136.[m
[31m-==> Start Training Epoch 137, lr=0.010000 ...[m
[31m-==> Finished Epoch 137.[m
[31m-==> Start Training Epoch 138, lr=0.010000 ...[m
[31m-==> Finished Epoch 138.[m
[31m-==> Start Training Epoch 139, lr=0.010000 ...[m
[31m-==> Finished Epoch 139.[m
[31m-==> Start Training Epoch 140, lr=0.010000 ...[m
[31m-==> Finished Epoch 140.[m
[31m-++> Evaluate at epoch 140 ...[m
[31m-PSNR = 20.925771 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 140 Finished.[m
[31m-==> Start Training Epoch 141, lr=0.010000 ...[m
[31m-==> Finished Epoch 141.[m
[31m-==> Start Training Epoch 142, lr=0.010000 ...[m
[31m-==> Finished Epoch 142.[m
[31m-==> Start Training Epoch 143, lr=0.010000 ...[m
[31m-==> Finished Epoch 143.[m
[31m-==> Start Training Epoch 144, lr=0.010000 ...[m
[31m-==> Finished Epoch 144.[m
[31m-==> Start Training Epoch 145, lr=0.010000 ...[m
[31m-==> Finished Epoch 145.[m
[31m-==> Start Training Epoch 146, lr=0.010000 ...[m
[31m-==> Finished Epoch 146.[m
[31m-==> Start Training Epoch 147, lr=0.010000 ...[m
[31m-==> Finished Epoch 147.[m
[31m-==> Start Training Epoch 148, lr=0.010000 ...[m
[31m-==> Finished Epoch 148.[m
[31m-==> Start Training Epoch 149, lr=0.010000 ...[m
[31m-==> Finished Epoch 149.[m
[31m-==> Start Training Epoch 150, lr=0.010000 ...[m
[31m-==> Finished Epoch 150.[m
[31m-++> Evaluate at epoch 150 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_01-15-38 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0150.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 150, global step 1800[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 151, lr=0.010000 ...[m
[31m-==> Finished Epoch 151.[m
[31m-==> Start Training Epoch 152, lr=0.008404 ...[m
[31m-==> Finished Epoch 152.[m
[31m-==> Start Training Epoch 153, lr=0.008395 ...[m
[31m-==> Finished Epoch 153.[m
[31m-==> Start Training Epoch 154, lr=0.008385 ...[m
[31m-==> Finished Epoch 154.[m
[31m-==> Start Training Epoch 155, lr=0.008375 ...[m
[31m-==> Finished Epoch 155.[m
[31m-==> Start Training Epoch 156, lr=0.008366 ...[m
[31m-==> Finished Epoch 156.[m
[31m-==> Start Training Epoch 157, lr=0.008356 ...[m
[31m-==> Finished Epoch 157.[m
[31m-==> Start Training Epoch 158, lr=0.008346 ...[m
[31m-==> Finished Epoch 158.[m
[31m-==> Start Training Epoch 159, lr=0.008337 ...[m
[31m-==> Finished Epoch 159.[m
[31m-==> Start Training Epoch 160, lr=0.008327 ...[m
[31m-==> Finished Epoch 160.[m
[31m-++> Evaluate at epoch 160 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-25-46 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-27-10 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-32-51 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-34-00 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-39-49 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-40-40 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-42-44 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-43-14 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-44-02 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0160.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 160, global step 1920[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-==> Finished Epoch 161.[m
[31m-==> Start Training Epoch 162, lr=0.008308 ...[m
[31m-==> Finished Epoch 162.[m
[31m-==> Start Training Epoch 163, lr=0.008299 ...[m
[31m-==> Finished Epoch 163.[m
[31m-==> Start Training Epoch 164, lr=0.008289 ...[m
[31m-==> Finished Epoch 164.[m
[31m-==> Start Training Epoch 165, lr=0.008279 ...[m
[31m-==> Finished Epoch 165.[m
[31m-==> Start Training Epoch 166, lr=0.008270 ...[m
[31m-==> Finished Epoch 166.[m
[31m-==> Start Training Epoch 167, lr=0.008260 ...[m
[31m-==> Finished Epoch 167.[m
[31m-==> Start Training Epoch 168, lr=0.008251 ...[m
[31m-==> Finished Epoch 168.[m
[31m-==> Start Training Epoch 169, lr=0.008241 ...[m
[31m-==> Finished Epoch 169.[m
[31m-==> Start Training Epoch 170, lr=0.008232 ...[m
[31m-==> Finished Epoch 170.[m
[31m-++> Evaluate at epoch 170 ...[m
[31m-PSNR = 21.230199 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 170 Finished.[m
[31m-[INFO] New best result: 0.008297114555413524 --> 0.008017054002266377[m
[31m-==> Start Training Epoch 171, lr=0.008222 ...[m
[31m-==> Finished Epoch 171.[m
[31m-==> Start Training Epoch 172, lr=0.008213 ...[m
[31m-==> Finished Epoch 172.[m
[31m-==> Start Training Epoch 173, lr=0.008204 ...[m
[31m-==> Finished Epoch 173.[m
[31m-==> Start Training Epoch 174, lr=0.008194 ...[m
[31m-==> Finished Epoch 174.[m
[31m-==> Start Training Epoch 175, lr=0.008185 ...[m
[31m-==> Finished Epoch 175.[m
[31m-==> Start Training Epoch 176, lr=0.008175 ...[m
[31m-==> Finished Epoch 176.[m
[31m-==> Start Training Epoch 177, lr=0.008166 ...[m
[31m-==> Finished Epoch 177.[m
[31m-==> Start Training Epoch 178, lr=0.008156 ...[m
[31m-==> Finished Epoch 178.[m
[31m-==> Start Training Epoch 179, lr=0.008147 ...[m
[31m-==> Finished Epoch 179.[m
[31m-==> Start Training Epoch 180, lr=0.008138 ...[m
[31m-==> Finished Epoch 180.[m
[31m-++> Evaluate at epoch 180 ...[m
[31m-PSNR = 21.440616 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 180 Finished.[m
[31m-[INFO] New best result: 0.008017054002266377 --> 0.007678820635192096[m
[31m-==> Start Training Epoch 181, lr=0.008128 ...[m
[31m-==> Finished Epoch 181.[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-47-45 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0181.pth[m
[31m-[INFO] Trainer: ngp | 2022-08-16_11-47-59 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0180.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 180, global step 2160[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 181, lr=0.008128 ...[m
[31m-==> Finished Epoch 181.[m
[31m-==> Start Training Epoch 182, lr=0.008119 ...[m
[31m-==> Finished Epoch 182.[m
[31m-==> Start Training Epoch 183, lr=0.008110 ...[m
[31m-==> Finished Epoch 183.[m
[31m-==> Start Training Epoch 184, lr=0.008100 ...[m
[31m-==> Finished Epoch 184.[m
[31m-==> Start Training Epoch 185, lr=0.008091 ...[m
[31m-==> Finished Epoch 185.[m
[31m-==> Start Training Epoch 186, lr=0.008082 ...[m
[31m-==> Finished Epoch 186.[m
[31m-==> Start Training Epoch 187, lr=0.008072 ...[m
[31m-==> Finished Epoch 187.[m
[31m-==> Start Training Epoch 188, lr=0.008063 ...[m
[31m-==> Finished Epoch 188.[m
[31m-==> Start Training Epoch 189, lr=0.008054 ...[m
[31m-==> Finished Epoch 189.[m
[31m-==> Start Training Epoch 190, lr=0.008045 ...[m
[31m-==> Finished Epoch 190.[m
[31m-++> Evaluate at epoch 190 ...[m
[31m-PSNR = 21.562248 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 190 Finished.[m
[31m-[INFO] New best result: 0.008017054002266377 --> 0.007495616446249187[m
[31m-==> Start Training Epoch 191, lr=0.008035 ...[m
[31m-==> Finished Epoch 191.[m
[31m-==> Start Training Epoch 192, lr=0.008026 ...[m
[31m-==> Finished Epoch 192.[m
[31m-==> Start Training Epoch 193, lr=0.008017 ...[m
[31m-==> Finished Epoch 193.[m
[31m-==> Start Training Epoch 194, lr=0.008008 ...[m
[31m-==> Finished Epoch 194.[m
[31m-==> Start Training Epoch 195, lr=0.007998 ...[m
[31m-==> Finished Epoch 195.[m
[31m-==> Start Training Epoch 196, lr=0.007989 ...[m
[31m-==> Finished Epoch 196.[m
[31m-==> Start Training Epoch 197, lr=0.007980 ...[m
[31m-==> Finished Epoch 197.[m
[31m-==> Start Training Epoch 198, lr=0.007971 ...[m
[31m-==> Finished Epoch 198.[m
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660439669.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660439669.skhalid-MS-7A94[m
[1mnew file mode 100644[m
[1mindex 0000000..db048a6[m
Binary files /dev/null and b/Umbrella/run/ngp/events.out.tfevents.1660439669.skhalid-MS-7A94 differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660625360.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660625360.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 85b1616..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660625360.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660625386.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660625386.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 3f66fac..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660625386.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660625423.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660625423.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex ecf9d24..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660625423.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660625666.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660625666.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 7f1aaf8..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660625666.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660626466.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660626466.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex f584c88..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660626466.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660626940.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660626940.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex e1ac31f..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660626940.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660663548.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660663548.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 1d86904..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660663548.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660663631.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660663631.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex b44b75d..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660663631.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660663972.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660663972.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 12b0bb0..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660663972.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664041.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664041.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 0a81cce..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664041.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664391.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664391.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex b8ea15d..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664391.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664441.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664441.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 5579268..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664441.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664566.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664566.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 3636e59..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664566.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664595.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664595.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 8e87b9e..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664595.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664643.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664643.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 82e0516..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664643.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella/run/ngp/events.out.tfevents.1660664881.skhalid-MS-7A94 b/Umbrella/run/ngp/events.out.tfevents.1660664881.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 20dd818..0000000[m
Binary files a/Umbrella/run/ngp/events.out.tfevents.1660664881.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/log_ngp.txt b/Umbrella_21.92_0.6420_0.236/log_ngp.txt[m
[1mdeleted file mode 100644[m
[1mindex bd3ff37..0000000[m
[1m--- a/Umbrella_21.92_0.6420_0.236/log_ngp.txt[m
[1m+++ /dev/null[m
[36m@@ -1,1215 +0,0 @@[m
[31m-[INFO] Trainer: ngp | 2022-08-15_23-21-22 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[WARN] No checkpoint found, model randomly initialized.[m
[31m-==> Start Training Epoch 1, lr=0.010000 ...[m
[31m-==> Finished Epoch 1.[m
[31m-==> Start Training Epoch 2, lr=0.009988 ...[m
[31m-==> Finished Epoch 2.[m
[31m-==> Start Training Epoch 3, lr=0.009977 ...[m
[31m-==> Finished Epoch 3.[m
[31m-==> Start Training Epoch 4, lr=0.009966 ...[m
[31m-==> Finished Epoch 4.[m
[31m-[INFO] Trainer: ngp | 2022-08-15_23-21-51 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0004.pth[m
[31m-[INFO] Trainer: ngp | 2022-08-15_23-22-12 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0003.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 3, global step 36[m
[31m-[INFO] loaded optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 4, lr=0.009966 ...[m
[31m-==> Finished Epoch 4.[m
[31m-==> Start Training Epoch 5, lr=0.009954 ...[m
[31m-==> Finished Epoch 5.[m
[31m-==> Start Training Epoch 6, lr=0.009943 ...[m
[31m-==> Finished Epoch 6.[m
[31m-==> Start Training Epoch 7, lr=0.009931 ...[m
[31m-==> Finished Epoch 7.[m
[31m-==> Start Training Epoch 8, lr=0.009920 ...[m
[31m-==> Finished Epoch 8.[m
[31m-==> Start Training Epoch 9, lr=0.009908 ...[m
[31m-==> Finished Epoch 9.[m
[31m-==> Start Training Epoch 10, lr=0.009897 ...[m
[31m-==> Finished Epoch 10.[m
[31m-++> Evaluate at epoch 10 ...[m
[31m-PSNR = 18.898819 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 10 Finished.[m
[31m-[INFO] New best result: None --> 0.012897956340263287[m
[31m-==> Start Training Epoch 11, lr=0.009886 ...[m
[31m-==> Finished Epoch 11.[m
[31m-==> Start Training Epoch 12, lr=0.009874 ...[m
[31m-==> Finished Epoch 12.[m
[31m-==> Start Training Epoch 13, lr=0.009863 ...[m
[31m-==> Finished Epoch 13.[m
[31m-==> Start Training Epoch 14, lr=0.009851 ...[m
[31m-==> Finished Epoch 14.[m
[31m-==> Start Training Epoch 15, lr=0.009840 ...[m
[31m-==> Finished Epoch 15.[m
[31m-==> Start Training Epoch 16, lr=0.009829 ...[m
[31m-==> Finished Epoch 16.[m
[31m-==> Start Training Epoch 17, lr=0.009817 ...[m
[31m-==> Finished Epoch 17.[m
[31m-==> Start Training Epoch 18, lr=0.009806 ...[m
[31m-==> Finished Epoch 18.[m
[31m-==> Start Training Epoch 19, lr=0.009795 ...[m
[31m-==> Finished Epoch 19.[m
[31m-==> Start Training Epoch 20, lr=0.009784 ...[m
[31m-==> Finished Epoch 20.[m
[31m-++> Evaluate at epoch 20 ...[m
[31m-PSNR = 19.445517 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 20 Finished.[m
[31m-[INFO] New best result: 0.012897956340263287 --> 0.011378627658511201[m
[31m-==> Start Training Epoch 21, lr=0.009772 ...[m
[31m-==> Finished Epoch 21.[m
[31m-==> Start Training Epoch 22, lr=0.009761 ...[m
[31m-==> Finished Epoch 22.[m
[31m-==> Start Training Epoch 23, lr=0.009750 ...[m
[31m-==> Finished Epoch 23.[m
[31m-==> Start Training Epoch 24, lr=0.009739 ...[m
[31m-==> Finished Epoch 24.[m
[31m-==> Start Training Epoch 25, lr=0.009727 ...[m
[31m-==> Finished Epoch 25.[m
[31m-==> Start Training Epoch 26, lr=0.009716 ...[m
[31m-==> Finished Epoch 26.[m
[31m-==> Start Training Epoch 27, lr=0.009705 ...[m
[31m-==> Finished Epoch 27.[m
[31m-==> Start Training Epoch 28, lr=0.009694 ...[m
[31m-==> Finished Epoch 28.[m
[31m-==> Start Training Epoch 29, lr=0.009683 ...[m
[31m-==> Finished Epoch 29.[m
[31m-==> Start Training Epoch 30, lr=0.009672 ...[m
[31m-==> Finished Epoch 30.[m
[31m-++> Evaluate at epoch 30 ...[m
[31m-PSNR = 19.677816 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 30 Finished.[m
[31m-[INFO] New best result: 0.011378627658511201 --> 0.010790284257382154[m
[31m-==> Start Training Epoch 31, lr=0.009661 ...[m
[31m-==> Finished Epoch 31.[m
[31m-==> Start Training Epoch 32, lr=0.009649 ...[m
[31m-==> Finished Epoch 32.[m
[31m-==> Start Training Epoch 33, lr=0.009638 ...[m
[31m-==> Finished Epoch 33.[m
[31m-==> Start Training Epoch 34, lr=0.009627 ...[m
[31m-==> Finished Epoch 34.[m
[31m-==> Start Training Epoch 35, lr=0.009616 ...[m
[31m-==> Finished Epoch 35.[m
[31m-==> Start Training Epoch 36, lr=0.009605 ...[m
[31m-==> Finished Epoch 36.[m
[31m-==> Start Training Epoch 37, lr=0.009594 ...[m
[31m-==> Finished Epoch 37.[m
[31m-==> Start Training Epoch 38, lr=0.009583 ...[m
[31m-==> Finished Epoch 38.[m
[31m-==> Start Training Epoch 39, lr=0.009572 ...[m
[31m-==> Finished Epoch 39.[m
[31m-==> Start Training Epoch 40, lr=0.009561 ...[m
[31m-==> Finished Epoch 40.[m
[31m-++> Evaluate at epoch 40 ...[m
[31m-PSNR = 19.857245 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 40 Finished.[m
[31m-[INFO] New best result: 0.010790284257382154 --> 0.01035767700523138[m
[31m-==> Start Training Epoch 41, lr=0.009550 ...[m
[31m-==> Finished Epoch 41.[m
[31m-==> Start Training Epoch 42, lr=0.009539 ...[m
[31m-==> Finished Epoch 42.[m
[31m-==> Start Training Epoch 43, lr=0.009528 ...[m
[31m-==> Finished Epoch 43.[m
[31m-==> Start Training Epoch 44, lr=0.009517 ...[m
[31m-==> Finished Epoch 44.[m
[31m-==> Start Training Epoch 45, lr=0.009506 ...[m
[31m-==> Finished Epoch 45.[m
[31m-==> Start Training Epoch 46, lr=0.009495 ...[m
[31m-==> Finished Epoch 46.[m
[31m-==> Start Training Epoch 47, lr=0.009484 ...[m
[31m-==> Finished Epoch 47.[m
[31m-==> Start Training Epoch 48, lr=0.009473 ...[m
[31m-==> Finished Epoch 48.[m
[31m-==> Start Training Epoch 49, lr=0.009462 ...[m
[31m-==> Finished Epoch 49.[m
[31m-==> Start Training Epoch 50, lr=0.009451 ...[m
[31m-==> Finished Epoch 50.[m
[31m-++> Evaluate at epoch 50 ...[m
[31m-PSNR = 19.935897 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 50 Finished.[m
[31m-[INFO] New best result: 0.01035767700523138 --> 0.010174437270810207[m
[31m-==> Start Training Epoch 51, lr=0.009441 ...[m
[31m-==> Finished Epoch 51.[m
[31m-==> Start Training Epoch 52, lr=0.009430 ...[m
[31m-==> Finished Epoch 52.[m
[31m-==> Start Training Epoch 53, lr=0.009419 ...[m
[31m-==> Finished Epoch 53.[m
[31m-==> Start Training Epoch 54, lr=0.009408 ...[m
[31m-==> Finished Epoch 54.[m
[31m-==> Start Training Epoch 55, lr=0.009397 ...[m
[31m-==> Finished Epoch 55.[m
[31m-==> Start Training Epoch 56, lr=0.009386 ...[m
[31m-==> Finished Epoch 56.[m
[31m-==> Start Training Epoch 57, lr=0.009376 ...[m
[31m-==> Finished Epoch 57.[m
[31m-==> Start Training Epoch 58, lr=0.009365 ...[m
[31m-==> Finished Epoch 58.[m
[31m-==> Start Training Epoch 59, lr=0.009354 ...[m
[31m-==> Finished Epoch 59.[m
[31m-==> Start Training Epoch 60, lr=0.009343 ...[m
[31m-==> Finished Epoch 60.[m
[31m-++> Evaluate at epoch 60 ...[m
[31m-PSNR = 19.981935 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 60 Finished.[m
[31m-[INFO] New best result: 0.010174437270810207 --> 0.010069662239402533[m
[31m-==> Start Training Epoch 61, lr=0.009333 ...[m
[31m-==> Finished Epoch 61.[m
[31m-==> Start Training Epoch 62, lr=0.009322 ...[m
[31m-==> Finished Epoch 62.[m
[31m-==> Start Training Epoch 63, lr=0.009311 ...[m
[31m-==> Finished Epoch 63.[m
[31m-==> Start Training Epoch 64, lr=0.009300 ...[m
[31m-==> Finished Epoch 64.[m
[31m-==> Start Training Epoch 65, lr=0.009290 ...[m
[31m-==> Finished Epoch 65.[m
[31m-==> Start Training Epoch 66, lr=0.009279 ...[m
[31m-==> Finished Epoch 66.[m
[31m-==> Start Training Epoch 67, lr=0.009268 ...[m
[31m-==> Finished Epoch 67.[m
[31m-==> Start Training Epoch 68, lr=0.009258 ...[m
[31m-==> Finished Epoch 68.[m
[31m-==> Start Training Epoch 69, lr=0.009247 ...[m
[31m-==> Finished Epoch 69.[m
[31m-==> Start Training Epoch 70, lr=0.009236 ...[m
[31m-==> Finished Epoch 70.[m
[31m-++> Evaluate at epoch 70 ...[m
[31m-PSNR = 20.017089 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 70 Finished.[m
[31m-[INFO] New best result: 0.010069662239402533 --> 0.009990849687407414[m
[31m-==> Start Training Epoch 71, lr=0.009226 ...[m
[31m-==> Finished Epoch 71.[m
[31m-==> Start Training Epoch 72, lr=0.009215 ...[m
[31m-==> Finished Epoch 72.[m
[31m-==> Start Training Epoch 73, lr=0.009204 ...[m
[31m-==> Finished Epoch 73.[m
[31m-==> Start Training Epoch 74, lr=0.009194 ...[m
[31m-==> Finished Epoch 74.[m
[31m-==> Start Training Epoch 75, lr=0.009183 ...[m
[31m-==> Finished Epoch 75.[m
[31m-==> Start Training Epoch 76, lr=0.009173 ...[m
[31m-==> Finished Epoch 76.[m
[31m-==> Start Training Epoch 77, lr=0.009162 ...[m
[31m-==> Finished Epoch 77.[m
[31m-==> Start Training Epoch 78, lr=0.009152 ...[m
[31m-==> Finished Epoch 78.[m
[31m-==> Start Training Epoch 79, lr=0.009141 ...[m
[31m-==> Finished Epoch 79.[m
[31m-==> Start Training Epoch 80, lr=0.009131 ...[m
[31m-==> Finished Epoch 80.[m
[31m-++> Evaluate at epoch 80 ...[m
[31m-PSNR = 20.047833 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 80 Finished.[m
[31m-[INFO] New best result: 0.009990849687407414 --> 0.009922626738746962[m
[31m-==> Start Training Epoch 81, lr=0.009120 ...[m
[31m-==> Finished Epoch 81.[m
[31m-==> Start Training Epoch 82, lr=0.009110 ...[m
[31m-==> Finished Epoch 82.[m
[31m-==> Start Training Epoch 83, lr=0.009099 ...[m
[31m-==> Finished Epoch 83.[m
[31m-==> Start Training Epoch 84, lr=0.009089 ...[m
[31m-==> Finished Epoch 84.[m
[31m-==> Start Training Epoch 85, lr=0.009078 ...[m
[31m-==> Finished Epoch 85.[m
[31m-==> Start Training Epoch 86, lr=0.009068 ...[m
[31m-==> Finished Epoch 86.[m
[31m-==> Start Training Epoch 87, lr=0.009057 ...[m
[31m-==> Finished Epoch 87.[m
[31m-==> Start Training Epoch 88, lr=0.009047 ...[m
[31m-==> Finished Epoch 88.[m
[31m-==> Start Training Epoch 89, lr=0.009036 ...[m
[31m-==> Finished Epoch 89.[m
[31m-==> Start Training Epoch 90, lr=0.009026 ...[m
[31m-==> Finished Epoch 90.[m
[31m-++> Evaluate at epoch 90 ...[m
[31m-PSNR = 20.076895 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 90 Finished.[m
[31m-[INFO] New best result: 0.009922626738746962 --> 0.009858960208172599[m
[31m-==> Start Training Epoch 91, lr=0.009016 ...[m
[31m-==> Finished Epoch 91.[m
[31m-==> Start Training Epoch 92, lr=0.009005 ...[m
[31m-==> Finished Epoch 92.[m
[31m-==> Start Training Epoch 93, lr=0.008995 ...[m
[31m-==> Finished Epoch 93.[m
[31m-==> Start Training Epoch 94, lr=0.008985 ...[m
[31m-==> Finished Epoch 94.[m
[31m-==> Start Training Epoch 95, lr=0.008974 ...[m
[31m-==> Finished Epoch 95.[m
[31m-==> Start Training Epoch 96, lr=0.008964 ...[m
[31m-==> Finished Epoch 96.[m
[31m-==> Start Training Epoch 97, lr=0.008954 ...[m
[31m-==> Finished Epoch 97.[m
[31m-==> Start Training Epoch 98, lr=0.008943 ...[m
[31m-==> Finished Epoch 98.[m
[31m-==> Start Training Epoch 99, lr=0.008933 ...[m
[31m-==> Finished Epoch 99.[m
[31m-==> Start Training Epoch 100, lr=0.008923 ...[m
[31m-==> Finished Epoch 100.[m
[31m-++> Evaluate at epoch 100 ...[m
[31m-PSNR = 20.096146 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 100 Finished.[m
[31m-[INFO] New best result: 0.009858960208172599 --> 0.00981750680754582[m
[31m-==> Start Training Epoch 101, lr=0.008913 ...[m
[31m-==> Finished Epoch 101.[m
[31m-==> Start Training Epoch 102, lr=0.008902 ...[m
[31m-==> Finished Epoch 102.[m
[31m-==> Start Training Epoch 103, lr=0.008892 ...[m
[31m-==> Finished Epoch 103.[m
[31m-==> Start Training Epoch 104, lr=0.008882 ...[m
[31m-==> Finished Epoch 104.[m
[31m-==> Start Training Epoch 105, lr=0.008872 ...[m
[31m-==> Finished Epoch 105.[m
[31m-==> Start Training Epoch 106, lr=0.008861 ...[m
[31m-==> Finished Epoch 106.[m
[31m-==> Start Training Epoch 107, lr=0.008851 ...[m
[31m-==> Finished Epoch 107.[m
[31m-==> Start Training Epoch 108, lr=0.008841 ...[m
[31m-==> Finished Epoch 108.[m
[31m-==> Start Training Epoch 109, lr=0.008831 ...[m
[31m-==> Finished Epoch 109.[m
[31m-==> Start Training Epoch 110, lr=0.008821 ...[m
[31m-==> Finished Epoch 110.[m
[31m-++> Evaluate at epoch 110 ...[m
[31m-PSNR = 20.111510 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 110 Finished.[m
[31m-[INFO] New best result: 0.00981750680754582 --> 0.00978497276082635[m
[31m-==> Start Training Epoch 111, lr=0.008810 ...[m
[31m-==> Finished Epoch 111.[m
[31m-==> Start Training Epoch 112, lr=0.008800 ...[m
[31m-==> Finished Epoch 112.[m
[31m-==> Start Training Epoch 113, lr=0.008790 ...[m
[31m-==> Finished Epoch 113.[m
[31m-==> Start Training Epoch 114, lr=0.008780 ...[m
[31m-==> Finished Epoch 114.[m
[31m-==> Start Training Epoch 115, lr=0.008770 ...[m
[31m-==> Finished Epoch 115.[m
[31m-==> Start Training Epoch 116, lr=0.008760 ...[m
[31m-==> Finished Epoch 116.[m
[31m-==> Start Training Epoch 117, lr=0.008750 ...[m
[31m-==> Finished Epoch 117.[m
[31m-==> Start Training Epoch 118, lr=0.008740 ...[m
[31m-==> Finished Epoch 118.[m
[31m-==> Start Training Epoch 119, lr=0.008730 ...[m
[31m-==> Finished Epoch 119.[m
[31m-==> Start Training Epoch 120, lr=0.008720 ...[m
[31m-==> Finished Epoch 120.[m
[31m-++> Evaluate at epoch 120 ...[m
[31m-PSNR = 20.124233 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 120 Finished.[m
[31m-[INFO] New best result: 0.00978497276082635 --> 0.009758327777187029[m
[31m-==> Start Training Epoch 121, lr=0.008710 ...[m
[31m-==> Finished Epoch 121.[m
[31m-==> Start Training Epoch 122, lr=0.008700 ...[m
[31m-==> Finished Epoch 122.[m
[31m-==> Start Training Epoch 123, lr=0.008690 ...[m
[31m-==> Finished Epoch 123.[m
[31m-==> Start Training Epoch 124, lr=0.008680 ...[m
[31m-==> Finished Epoch 124.[m
[31m-==> Start Training Epoch 125, lr=0.008670 ...[m
[31m-==> Finished Epoch 125.[m
[31m-==> Start Training Epoch 126, lr=0.008660 ...[m
[31m-==> Finished Epoch 126.[m
[31m-==> Start Training Epoch 127, lr=0.008650 ...[m
[31m-==> Finished Epoch 127.[m
[31m-==> Start Training Epoch 128, lr=0.008640 ...[m
[31m-==> Finished Epoch 128.[m
[31m-==> Start Training Epoch 129, lr=0.008630 ...[m
[31m-==> Finished Epoch 129.[m
[31m-==> Start Training Epoch 130, lr=0.008620 ...[m
[31m-==> Finished Epoch 130.[m
[31m-++> Evaluate at epoch 130 ...[m
[31m-PSNR = 20.134163 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 130 Finished.[m
[31m-[INFO] New best result: 0.009758327777187029 --> 0.00973782199434936[m
[31m-==> Start Training Epoch 131, lr=0.008610 ...[m
[31m-==> Finished Epoch 131.[m
[31m-==> Start Training Epoch 132, lr=0.008600 ...[m
[31m-==> Finished Epoch 132.[m
[31m-==> Start Training Epoch 133, lr=0.008590 ...[m
[31m-==> Finished Epoch 133.[m
[31m-==> Start Training Epoch 134, lr=0.008580 ...[m
[31m-==> Finished Epoch 134.[m
[31m-==> Start Training Epoch 135, lr=0.008570 ...[m
[31m-==> Finished Epoch 135.[m
[31m-==> Start Training Epoch 136, lr=0.008561 ...[m
[31m-==> Finished Epoch 136.[m
[31m-==> Start Training Epoch 137, lr=0.008551 ...[m
[31m-==> Finished Epoch 137.[m
[31m-==> Start Training Epoch 138, lr=0.008541 ...[m
[31m-==> Finished Epoch 138.[m
[31m-==> Start Training Epoch 139, lr=0.008531 ...[m
[31m-==> Finished Epoch 139.[m
[31m-==> Start Training Epoch 140, lr=0.008521 ...[m
[31m-==> Finished Epoch 140.[m
[31m-++> Evaluate at epoch 140 ...[m
[31m-PSNR = 20.143474 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 140 Finished.[m
[31m-[INFO] New best result: 0.00973782199434936 --> 0.009718722042938074[m
[31m-==> Start Training Epoch 141, lr=0.008511 ...[m
[31m-==> Finished Epoch 141.[m
[31m-==> Start Training Epoch 142, lr=0.008502 ...[m
[31m-==> Finished Epoch 142.[m
[31m-==> Start Training Epoch 143, lr=0.008492 ...[m
[31m-==> Finished Epoch 143.[m
[31m-==> Start Training Epoch 144, lr=0.008482 ...[m
[31m-==> Finished Epoch 144.[m
[31m-==> Start Training Epoch 145, lr=0.008472 ...[m
[31m-==> Finished Epoch 145.[m
[31m-==> Start Training Epoch 146, lr=0.008463 ...[m
[31m-==> Finished Epoch 146.[m
[31m-==> Start Training Epoch 147, lr=0.008453 ...[m
[31m-==> Finished Epoch 147.[m
[31m-==> Start Training Epoch 148, lr=0.008443 ...[m
[31m-==> Finished Epoch 148.[m
[31m-==> Start Training Epoch 149, lr=0.008433 ...[m
[31m-==> Finished Epoch 149.[m
[31m-==> Start Training Epoch 150, lr=0.008424 ...[m
[31m-==> Finished Epoch 150.[m
[31m-++> Evaluate at epoch 150 ...[m
[31m-PSNR = 20.150761 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 150 Finished.[m
[31m-[INFO] New best result: 0.009718722042938074 --> 0.009704026859253645[m
[31m-==> Start Training Epoch 151, lr=0.008414 ...[m
[31m-==> Finished Epoch 151.[m
[31m-==> Start Training Epoch 152, lr=0.008404 ...[m
[31m-==> Finished Epoch 152.[m
[31m-==> Start Training Epoch 153, lr=0.008395 ...[m
[31m-==> Finished Epoch 153.[m
[31m-==> Start Training Epoch 154, lr=0.008385 ...[m
[31m-==> Finished Epoch 154.[m
[31m-==> Start Training Epoch 155, lr=0.008375 ...[m
[31m-==> Finished Epoch 155.[m
[31m-==> Start Training Epoch 156, lr=0.008366 ...[m
[31m-==> Finished Epoch 156.[m
[31m-==> Start Training Epoch 157, lr=0.008356 ...[m
[31m-==> Finished Epoch 157.[m
[31m-==> Start Training Epoch 158, lr=0.008346 ...[m
[31m-==> Finished Epoch 158.[m
[31m-==> Start Training Epoch 159, lr=0.008337 ...[m
[31m-==> Finished Epoch 159.[m
[31m-==> Start Training Epoch 160, lr=0.008327 ...[m
[31m-==> Finished Epoch 160.[m
[31m-++> Evaluate at epoch 160 ...[m
[31m-PSNR = 20.157970 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 160 Finished.[m
[31m-[INFO] New best result: 0.009704026859253645 --> 0.009689573586607972[m
[31m-==> Start Training Epoch 161, lr=0.008318 ...[m
[31m-==> Finished Epoch 161.[m
[31m-==> Start Training Epoch 162, lr=0.008308 ...[m
[31m-==> Finished Epoch 162.[m
[31m-==> Start Training Epoch 163, lr=0.008299 ...[m
[31m-==> Finished Epoch 163.[m
[31m-==> Start Training Epoch 164, lr=0.008289 ...[m
[31m-==> Finished Epoch 164.[m
[31m-==> Start Training Epoch 165, lr=0.008279 ...[m
[31m-==> Finished Epoch 165.[m
[31m-==> Start Training Epoch 166, lr=0.008270 ...[m
[31m-==> Finished Epoch 166.[m
[31m-==> Start Training Epoch 167, lr=0.008260 ...[m
[31m-==> Finished Epoch 167.[m
[31m-==> Start Training Epoch 168, lr=0.008251 ...[m
[31m-==> Finished Epoch 168.[m
[31m-==> Start Training Epoch 169, lr=0.008241 ...[m
[31m-==> Finished Epoch 169.[m
[31m-==> Start Training Epoch 170, lr=0.008232 ...[m
[31m-==> Finished Epoch 170.[m
[31m-++> Evaluate at epoch 170 ...[m
[31m-PSNR = 20.163503 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 170 Finished.[m
[31m-[INFO] New best result: 0.009689573586607972 --> 0.009678841646139821[m
[31m-==> Start Training Epoch 171, lr=0.008222 ...[m
[31m-==> Finished Epoch 171.[m
[31m-==> Start Training Epoch 172, lr=0.008213 ...[m
[31m-==> Finished Epoch 172.[m
[31m-==> Start Training Epoch 173, lr=0.008204 ...[m
[31m-==> Finished Epoch 173.[m
[31m-==> Start Training Epoch 174, lr=0.008194 ...[m
[31m-==> Finished Epoch 174.[m
[31m-==> Start Training Epoch 175, lr=0.008185 ...[m
[31m-==> Finished Epoch 175.[m
[31m-==> Start Training Epoch 176, lr=0.008175 ...[m
[31m-==> Finished Epoch 176.[m
[31m-==> Start Training Epoch 177, lr=0.008166 ...[m
[31m-==> Finished Epoch 177.[m
[31m-==> Start Training Epoch 178, lr=0.008156 ...[m
[31m-==> Finished Epoch 178.[m
[31m-==> Start Training Epoch 179, lr=0.008147 ...[m
[31m-==> Finished Epoch 179.[m
[31m-==> Start Training Epoch 180, lr=0.008138 ...[m
[31m-==> Finished Epoch 180.[m
[31m-++> Evaluate at epoch 180 ...[m
[31m-PSNR = 20.169200 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 180 Finished.[m
[31m-[INFO] New best result: 0.009678841646139821 --> 0.009667698953611156[m
[31m-==> Start Training Epoch 181, lr=0.008128 ...[m
[31m-==> Finished Epoch 181.[m
[31m-==> Start Training Epoch 182, lr=0.008119 ...[m
[31m-==> Finished Epoch 182.[m
[31m-==> Start Training Epoch 183, lr=0.008110 ...[m
[31m-==> Finished Epoch 183.[m
[31m-==> Start Training Epoch 184, lr=0.008100 ...[m
[31m-==> Finished Epoch 184.[m
[31m-==> Start Training Epoch 185, lr=0.008091 ...[m
[31m-==> Finished Epoch 185.[m
[31m-==> Start Training Epoch 186, lr=0.008082 ...[m
[31m-==> Finished Epoch 186.[m
[31m-==> Start Training Epoch 187, lr=0.008072 ...[m
[31m-==> Finished Epoch 187.[m
[31m-==> Start Training Epoch 188, lr=0.008063 ...[m
[31m-==> Finished Epoch 188.[m
[31m-==> Start Training Epoch 189, lr=0.008054 ...[m
[31m-==> Finished Epoch 189.[m
[31m-==> Start Training Epoch 190, lr=0.008045 ...[m
[31m-==> Finished Epoch 190.[m
[31m-++> Evaluate at epoch 190 ...[m
[31m-PSNR = 20.174213 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 190 Finished.[m
[31m-[INFO] New best result: 0.009667698953611156 --> 0.009657998957360784[m
[31m-==> Start Training Epoch 191, lr=0.008035 ...[m
[31m-==> Finished Epoch 191.[m
[31m-==> Start Training Epoch 192, lr=0.008026 ...[m
[31m-==> Finished Epoch 192.[m
[31m-==> Start Training Epoch 193, lr=0.008017 ...[m
[31m-==> Finished Epoch 193.[m
[31m-==> Start Training Epoch 194, lr=0.008008 ...[m
[31m-==> Finished Epoch 194.[m
[31m-==> Start Training Epoch 195, lr=0.007998 ...[m
[31m-==> Finished Epoch 195.[m
[31m-==> Start Training Epoch 196, lr=0.007989 ...[m
[31m-==> Finished Epoch 196.[m
[31m-==> Start Training Epoch 197, lr=0.007980 ...[m
[31m-==> Finished Epoch 197.[m
[31m-==> Start Training Epoch 198, lr=0.007971 ...[m
[31m-==> Finished Epoch 198.[m
[31m-==> Start Training Epoch 199, lr=0.007962 ...[m
[31m-==> Finished Epoch 199.[m
[31m-==> Start Training Epoch 200, lr=0.007952 ...[m
[31m-==> Finished Epoch 200.[m
[31m-++> Evaluate at epoch 200 ...[m
[31m-PSNR = 20.179149 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 200 Finished.[m
[31m-[INFO] New best result: 0.009657998957360784 --> 0.009648550573425988[m
[31m-==> Start Training Epoch 201, lr=0.007943 ...[m
[31m-==> Finished Epoch 201.[m
[31m-==> Start Training Epoch 202, lr=0.010000 ...[m
[31m-==> Finished Epoch 202.[m
[31m-==> Start Training Epoch 203, lr=0.010000 ...[m
[31m-==> Finished Epoch 203.[m
[31m-==> Start Training Epoch 204, lr=0.010000 ...[m
[31m-==> Finished Epoch 204.[m
[31m-==> Start Training Epoch 205, lr=0.010000 ...[m
[31m-==> Finished Epoch 205.[m
[31m-==> Start Training Epoch 206, lr=0.010000 ...[m
[31m-==> Finished Epoch 206.[m
[31m-==> Start Training Epoch 207, lr=0.010000 ...[m
[31m-==> Finished Epoch 207.[m
[31m-==> Start Training Epoch 208, lr=0.010000 ...[m
[31m-==> Finished Epoch 208.[m
[31m-==> Start Training Epoch 209, lr=0.010000 ...[m
[31m-==> Finished Epoch 209.[m
[31m-==> Start Training Epoch 210, lr=0.010000 ...[m
[31m-==> Finished Epoch 210.[m
[31m-++> Evaluate at epoch 210 ...[m
[31m-PSNR = 20.461715 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 210 Finished.[m
[31m-[INFO] New best result: 0.009648550573425988 --> 0.009062742969642082[m
[31m-==> Start Training Epoch 211, lr=0.010000 ...[m
[31m-==> Finished Epoch 211.[m
[31m-==> Start Training Epoch 212, lr=0.010000 ...[m
[31m-==> Finished Epoch 212.[m
[31m-==> Start Training Epoch 213, lr=0.010000 ...[m
[31m-==> Finished Epoch 213.[m
[31m-==> Start Training Epoch 214, lr=0.010000 ...[m
[31m-==> Finished Epoch 214.[m
[31m-==> Start Training Epoch 215, lr=0.010000 ...[m
[31m-==> Finished Epoch 215.[m
[31m-==> Start Training Epoch 216, lr=0.010000 ...[m
[31m-==> Finished Epoch 216.[m
[31m-==> Start Training Epoch 217, lr=0.010000 ...[m
[31m-==> Finished Epoch 217.[m
[31m-==> Start Training Epoch 218, lr=0.010000 ...[m
[31m-==> Finished Epoch 218.[m
[31m-==> Start Training Epoch 219, lr=0.010000 ...[m
[31m-==> Finished Epoch 219.[m
[31m-==> Start Training Epoch 220, lr=0.010000 ...[m
[31m-==> Finished Epoch 220.[m
[31m-++> Evaluate at epoch 220 ...[m
[31m-PSNR = 20.870736 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 220 Finished.[m
[31m-[INFO] New best result: 0.009062742969642082 --> 0.00828077302624782[m
[31m-==> Start Training Epoch 221, lr=0.010000 ...[m
[31m-==> Finished Epoch 221.[m
[31m-==> Start Training Epoch 222, lr=0.010000 ...[m
[31m-==> Finished Epoch 222.[m
[31m-==> Start Training Epoch 223, lr=0.010000 ...[m
[31m-==> Finished Epoch 223.[m
[31m-==> Start Training Epoch 224, lr=0.010000 ...[m
[31m-==> Finished Epoch 224.[m
[31m-==> Start Training Epoch 225, lr=0.010000 ...[m
[31m-==> Finished Epoch 225.[m
[31m-==> Start Training Epoch 226, lr=0.010000 ...[m
[31m-==> Finished Epoch 226.[m
[31m-==> Start Training Epoch 227, lr=0.010000 ...[m
[31m-==> Finished Epoch 227.[m
[31m-==> Start Training Epoch 228, lr=0.010000 ...[m
[31m-==> Finished Epoch 228.[m
[31m-==> Start Training Epoch 229, lr=0.010000 ...[m
[31m-==> Finished Epoch 229.[m
[31m-==> Start Training Epoch 230, lr=0.010000 ...[m
[31m-==> Finished Epoch 230.[m
[31m-++> Evaluate at epoch 230 ...[m
[31m-PSNR = 21.278229 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 230 Finished.[m
[31m-[INFO] New best result: 0.00828077302624782 --> 0.007575886673294008[m
[31m-==> Start Training Epoch 231, lr=0.010000 ...[m
[31m-==> Finished Epoch 231.[m
[31m-==> Start Training Epoch 232, lr=0.010000 ...[m
[31m-==> Finished Epoch 232.[m
[31m-==> Start Training Epoch 233, lr=0.010000 ...[m
[31m-==> Finished Epoch 233.[m
[31m-==> Start Training Epoch 234, lr=0.010000 ...[m
[31m-==> Finished Epoch 234.[m
[31m-==> Start Training Epoch 235, lr=0.010000 ...[m
[31m-==> Finished Epoch 235.[m
[31m-==> Start Training Epoch 236, lr=0.010000 ...[m
[31m-==> Finished Epoch 236.[m
[31m-==> Start Training Epoch 237, lr=0.010000 ...[m
[31m-==> Finished Epoch 237.[m
[31m-==> Start Training Epoch 238, lr=0.010000 ...[m
[31m-==> Finished Epoch 238.[m
[31m-==> Start Training Epoch 239, lr=0.010000 ...[m
[31m-==> Finished Epoch 239.[m
[31m-==> Start Training Epoch 240, lr=0.010000 ...[m
[31m-==> Finished Epoch 240.[m
[31m-++> Evaluate at epoch 240 ...[m
[31m-PSNR = 21.401417 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 240 Finished.[m
[31m-[INFO] New best result: 0.007575886673294008 --> 0.007400670282853146[m
[31m-==> Start Training Epoch 241, lr=0.010000 ...[m
[31m-==> Finished Epoch 241.[m
[31m-==> Start Training Epoch 242, lr=0.010000 ...[m
[31m-==> Finished Epoch 242.[m
[31m-==> Start Training Epoch 243, lr=0.010000 ...[m
[31m-==> Finished Epoch 243.[m
[31m-==> Start Training Epoch 244, lr=0.010000 ...[m
[31m-==> Finished Epoch 244.[m
[31m-==> Start Training Epoch 245, lr=0.010000 ...[m
[31m-==> Finished Epoch 245.[m
[31m-==> Start Training Epoch 246, lr=0.010000 ...[m
[31m-==> Finished Epoch 246.[m
[31m-==> Start Training Epoch 247, lr=0.010000 ...[m
[31m-==> Finished Epoch 247.[m
[31m-==> Start Training Epoch 248, lr=0.010000 ...[m
[31m-==> Finished Epoch 248.[m
[31m-==> Start Training Epoch 249, lr=0.010000 ...[m
[31m-==> Finished Epoch 249.[m
[31m-==> Start Training Epoch 250, lr=0.010000 ...[m
[31m-==> Finished Epoch 250.[m
[31m-++> Evaluate at epoch 250 ...[m
[31m-PSNR = 21.076806 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 250 Finished.[m
[31m-==> Start Training Epoch 251, lr=0.010000 ...[m
[31m-==> Finished Epoch 251.[m
[31m-==> Start Training Epoch 252, lr=0.010000 ...[m
[31m-==> Finished Epoch 252.[m
[31m-==> Start Training Epoch 253, lr=0.010000 ...[m
[31m-==> Finished Epoch 253.[m
[31m-==> Start Training Epoch 254, lr=0.010000 ...[m
[31m-==> Finished Epoch 254.[m
[31m-==> Start Training Epoch 255, lr=0.010000 ...[m
[31m-==> Finished Epoch 255.[m
[31m-==> Start Training Epoch 256, lr=0.010000 ...[m
[31m-==> Finished Epoch 256.[m
[31m-==> Start Training Epoch 257, lr=0.010000 ...[m
[31m-==> Finished Epoch 257.[m
[31m-==> Start Training Epoch 258, lr=0.010000 ...[m
[31m-==> Finished Epoch 258.[m
[31m-==> Start Training Epoch 259, lr=0.010000 ...[m
[31m-==> Finished Epoch 259.[m
[31m-==> Start Training Epoch 260, lr=0.010000 ...[m
[31m-==> Finished Epoch 260.[m
[31m-++> Evaluate at epoch 260 ...[m
[31m-PSNR = 20.601173 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 260 Finished.[m
[31m-==> Start Training Epoch 261, lr=0.010000 ...[m
[31m-==> Finished Epoch 261.[m
[31m-==> Start Training Epoch 262, lr=0.010000 ...[m
[31m-==> Finished Epoch 262.[m
[31m-==> Start Training Epoch 263, lr=0.010000 ...[m
[31m-==> Finished Epoch 263.[m
[31m-==> Start Training Epoch 264, lr=0.010000 ...[m
[31m-==> Finished Epoch 264.[m
[31m-==> Start Training Epoch 265, lr=0.010000 ...[m
[31m-==> Finished Epoch 265.[m
[31m-==> Start Training Epoch 266, lr=0.010000 ...[m
[31m-==> Finished Epoch 266.[m
[31m-==> Start Training Epoch 267, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-15_23-51-18 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0266.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 266, global step 3192[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 267, lr=0.010000 ...[m
[31m-==> Finished Epoch 267.[m
[31m-==> Start Training Epoch 268, lr=0.010000 ...[m
[31m-==> Finished Epoch 268.[m
[31m-==> Start Training Epoch 269, lr=0.010000 ...[m
[31m-==> Finished Epoch 269.[m
[31m-==> Start Training Epoch 270, lr=0.010000 ...[m
[31m-==> Finished Epoch 270.[m
[31m-++> Evaluate at epoch 270 ...[m
[31m-PSNR = 20.641590 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 270 Finished.[m
[31m-==> Start Training Epoch 271, lr=0.010000 ...[m
[31m-==> Finished Epoch 271.[m
[31m-==> Start Training Epoch 272, lr=0.010000 ...[m
[31m-==> Finished Epoch 272.[m
[31m-==> Start Training Epoch 273, lr=0.010000 ...[m
[31m-==> Finished Epoch 273.[m
[31m-==> Start Training Epoch 274, lr=0.010000 ...[m
[31m-==> Finished Epoch 274.[m
[31m-==> Start Training Epoch 275, lr=0.010000 ...[m
[31m-==> Finished Epoch 275.[m
[31m-==> Start Training Epoch 276, lr=0.010000 ...[m
[31m-==> Finished Epoch 276.[m
[31m-==> Start Training Epoch 277, lr=0.010000 ...[m
[31m-==> Finished Epoch 277.[m
[31m-==> Start Training Epoch 278, lr=0.010000 ...[m
[31m-==> Finished Epoch 278.[m
[31m-==> Start Training Epoch 279, lr=0.010000 ...[m
[31m-==> Finished Epoch 279.[m
[31m-==> Start Training Epoch 280, lr=0.010000 ...[m
[31m-==> Finished Epoch 280.[m
[31m-++> Evaluate at epoch 280 ...[m
[31m-PSNR = 21.472599 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 280 Finished.[m
[31m-==> Start Training Epoch 281, lr=0.010000 ...[m
[31m-==> Finished Epoch 281.[m
[31m-==> Start Training Epoch 282, lr=0.010000 ...[m
[31m-==> Finished Epoch 282.[m
[31m-==> Start Training Epoch 283, lr=0.010000 ...[m
[31m-==> Finished Epoch 283.[m
[31m-==> Start Training Epoch 284, lr=0.010000 ...[m
[31m-==> Finished Epoch 284.[m
[31m-==> Start Training Epoch 285, lr=0.010000 ...[m
[31m-==> Finished Epoch 285.[m
[31m-==> Start Training Epoch 286, lr=0.010000 ...[m
[31m-==> Finished Epoch 286.[m
[31m-==> Start Training Epoch 287, lr=0.010000 ...[m
[31m-==> Finished Epoch 287.[m
[31m-==> Start Training Epoch 288, lr=0.010000 ...[m
[31m-==> Finished Epoch 288.[m
[31m-==> Start Training Epoch 289, lr=0.010000 ...[m
[31m-==> Finished Epoch 289.[m
[31m-==> Start Training Epoch 290, lr=0.010000 ...[m
[31m-==> Finished Epoch 290.[m
[31m-++> Evaluate at epoch 290 ...[m
[31m-PSNR = 21.926386 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 290 Finished.[m
[31m-[INFO] New best result: 0.007400670282853146 --> 0.006992929886716108[m
[31m-==> Start Training Epoch 291, lr=0.010000 ...[m
[31m-==> Finished Epoch 291.[m
[31m-==> Start Training Epoch 292, lr=0.010000 ...[m
[31m-==> Finished Epoch 292.[m
[31m-==> Start Training Epoch 293, lr=0.010000 ...[m
[31m-==> Finished Epoch 293.[m
[31m-==> Start Training Epoch 294, lr=0.010000 ...[m
[31m-==> Finished Epoch 294.[m
[31m-==> Start Training Epoch 295, lr=0.010000 ...[m
[31m-==> Finished Epoch 295.[m
[31m-==> Start Training Epoch 296, lr=0.010000 ...[m
[31m-==> Finished Epoch 296.[m
[31m-==> Start Training Epoch 297, lr=0.010000 ...[m
[31m-==> Finished Epoch 297.[m
[31m-==> Start Training Epoch 298, lr=0.010000 ...[m
[31m-==> Finished Epoch 298.[m
[31m-==> Start Training Epoch 299, lr=0.010000 ...[m
[31m-==> Finished Epoch 299.[m
[31m-==> Start Training Epoch 300, lr=0.010000 ...[m
[31m-==> Finished Epoch 300.[m
[31m-++> Evaluate at epoch 300 ...[m
[31m-PSNR = 22.147948 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 300 Finished.[m
[31m-[INFO] New best result: 0.006992929886716108 --> 0.006721218562840174[m
[31m-==> Start Training Epoch 301, lr=0.010000 ...[m
[31m-==> Finished Epoch 301.[m
[31m-==> Start Training Epoch 302, lr=0.010000 ...[m
[31m-==> Finished Epoch 302.[m
[31m-==> Start Training Epoch 303, lr=0.010000 ...[m
[31m-==> Finished Epoch 303.[m
[31m-==> Start Training Epoch 304, lr=0.010000 ...[m
[31m-==> Finished Epoch 304.[m
[31m-==> Start Training Epoch 305, lr=0.010000 ...[m
[31m-==> Finished Epoch 305.[m
[31m-==> Start Training Epoch 306, lr=0.010000 ...[m
[31m-==> Finished Epoch 306.[m
[31m-==> Start Training Epoch 307, lr=0.010000 ...[m
[31m-==> Finished Epoch 307.[m
[31m-==> Start Training Epoch 308, lr=0.010000 ...[m
[31m-==> Finished Epoch 308.[m
[31m-==> Start Training Epoch 309, lr=0.010000 ...[m
[31m-==> Finished Epoch 309.[m
[31m-==> Start Training Epoch 310, lr=0.010000 ...[m
[31m-==> Finished Epoch 310.[m
[31m-++> Evaluate at epoch 310 ...[m
[31m-PSNR = 22.257547 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 310 Finished.[m
[31m-[INFO] New best result: 0.006721218562840174 --> 0.006590202043298632[m
[31m-==> Start Training Epoch 311, lr=0.010000 ...[m
[31m-==> Finished Epoch 311.[m
[31m-==> Start Training Epoch 312, lr=0.010000 ...[m
[31m-==> Finished Epoch 312.[m
[31m-==> Start Training Epoch 313, lr=0.010000 ...[m
[31m-==> Finished Epoch 313.[m
[31m-==> Start Training Epoch 314, lr=0.010000 ...[m
[31m-==> Finished Epoch 314.[m
[31m-==> Start Training Epoch 315, lr=0.010000 ...[m
[31m-==> Finished Epoch 315.[m
[31m-==> Start Training Epoch 316, lr=0.010000 ...[m
[31m-==> Finished Epoch 316.[m
[31m-==> Start Training Epoch 317, lr=0.010000 ...[m
[31m-==> Finished Epoch 317.[m
[31m-==> Start Training Epoch 318, lr=0.010000 ...[m
[31m-==> Finished Epoch 318.[m
[31m-==> Start Training Epoch 319, lr=0.010000 ...[m
[31m-==> Finished Epoch 319.[m
[31m-==> Start Training Epoch 320, lr=0.010000 ...[m
[31m-==> Finished Epoch 320.[m
[31m-++> Evaluate at epoch 320 ...[m
[31m-PSNR = 22.309946 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 320 Finished.[m
[31m-[INFO] New best result: 0.006590202043298632 --> 0.006521259822572271[m
[31m-==> Start Training Epoch 321, lr=0.010000 ...[m
[31m-==> Finished Epoch 321.[m
[31m-==> Start Training Epoch 322, lr=0.010000 ...[m
[31m-==> Finished Epoch 322.[m
[31m-==> Start Training Epoch 323, lr=0.010000 ...[m
[31m-==> Finished Epoch 323.[m
[31m-==> Start Training Epoch 324, lr=0.010000 ...[m
[31m-==> Finished Epoch 324.[m
[31m-==> Start Training Epoch 325, lr=0.010000 ...[m
[31m-==> Finished Epoch 325.[m
[31m-==> Start Training Epoch 326, lr=0.010000 ...[m
[31m-==> Finished Epoch 326.[m
[31m-==> Start Training Epoch 327, lr=0.010000 ...[m
[31m-==> Finished Epoch 327.[m
[31m-==> Start Training Epoch 328, lr=0.010000 ...[m
[31m-==> Finished Epoch 328.[m
[31m-==> Start Training Epoch 329, lr=0.010000 ...[m
[31m-==> Finished Epoch 329.[m
[31m-==> Start Training Epoch 330, lr=0.010000 ...[m
[31m-==> Finished Epoch 330.[m
[31m-++> Evaluate at epoch 330 ...[m
[31m-PSNR = 22.339289 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 330 Finished.[m
[31m-[INFO] New best result: 0.006521259822572271 --> 0.006471142269826184[m
[31m-==> Start Training Epoch 331, lr=0.010000 ...[m
[31m-==> Finished Epoch 331.[m
[31m-==> Start Training Epoch 332, lr=0.010000 ...[m
[31m-==> Finished Epoch 332.[m
[31m-==> Start Training Epoch 333, lr=0.010000 ...[m
[31m-==> Finished Epoch 333.[m
[31m-==> Start Training Epoch 334, lr=0.010000 ...[m
[31m-==> Finished Epoch 334.[m
[31m-==> Start Training Epoch 335, lr=0.010000 ...[m
[31m-==> Finished Epoch 335.[m
[31m-==> Start Training Epoch 336, lr=0.010000 ...[m
[31m-==> Finished Epoch 336.[m
[31m-==> Start Training Epoch 337, lr=0.010000 ...[m
[31m-==> Finished Epoch 337.[m
[31m-==> Start Training Epoch 338, lr=0.010000 ...[m
[31m-==> Finished Epoch 338.[m
[31m-==> Start Training Epoch 339, lr=0.010000 ...[m
[31m-==> Finished Epoch 339.[m
[31m-==> Start Training Epoch 340, lr=0.010000 ...[m
[31m-==> Finished Epoch 340.[m
[31m-++> Evaluate at epoch 340 ...[m
[31m-PSNR = 22.350564 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 340 Finished.[m
[31m-[INFO] New best result: 0.006471142269826184 --> 0.00644010027948146[m
[31m-==> Start Training Epoch 341, lr=0.010000 ...[m
[31m-==> Finished Epoch 341.[m
[31m-==> Start Training Epoch 342, lr=0.010000 ...[m
[31m-==> Finished Epoch 342.[m
[31m-==> Start Training Epoch 343, lr=0.010000 ...[m
[31m-==> Finished Epoch 343.[m
[31m-==> Start Training Epoch 344, lr=0.010000 ...[m
[31m-==> Finished Epoch 344.[m
[31m-==> Start Training Epoch 345, lr=0.010000 ...[m
[31m-==> Finished Epoch 345.[m
[31m-==> Start Training Epoch 346, lr=0.010000 ...[m
[31m-==> Finished Epoch 346.[m
[31m-==> Start Training Epoch 347, lr=0.010000 ...[m
[31m-==> Finished Epoch 347.[m
[31m-==> Start Training Epoch 348, lr=0.010000 ...[m
[31m-==> Finished Epoch 348.[m
[31m-==> Start Training Epoch 349, lr=0.010000 ...[m
[31m-==> Finished Epoch 349.[m
[31m-==> Start Training Epoch 350, lr=0.010000 ...[m
[31m-==> Finished Epoch 350.[m
[31m-++> Evaluate at epoch 350 ...[m
[31m-PSNR = 22.326446 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 350 Finished.[m
[31m-==> Start Training Epoch 351, lr=0.010000 ...[m
[31m-==> Finished Epoch 351.[m
[31m-==> Start Training Epoch 352, lr=0.010000 ...[m
[31m-==> Finished Epoch 352.[m
[31m-==> Start Training Epoch 353, lr=0.010000 ...[m
[31m-==> Finished Epoch 353.[m
[31m-==> Start Training Epoch 354, lr=0.010000 ...[m
[31m-==> Finished Epoch 354.[m
[31m-==> Start Training Epoch 355, lr=0.010000 ...[m
[31m-==> Finished Epoch 355.[m
[31m-==> Start Training Epoch 356, lr=0.010000 ...[m
[31m-==> Finished Epoch 356.[m
[31m-==> Start Training Epoch 357, lr=0.010000 ...[m
[31m-==> Finished Epoch 357.[m
[31m-==> Start Training Epoch 358, lr=0.010000 ...[m
[31m-==> Finished Epoch 358.[m
[31m-==> Start Training Epoch 359, lr=0.010000 ...[m
[31m-==> Finished Epoch 359.[m
[31m-==> Start Training Epoch 360, lr=0.010000 ...[m
[31m-==> Finished Epoch 360.[m
[31m-++> Evaluate at epoch 360 ...[m
[31m-PSNR = 22.301035 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 360 Finished.[m
[31m-==> Start Training Epoch 361, lr=0.010000 ...[m
[31m-==> Finished Epoch 361.[m
[31m-==> Start Training Epoch 362, lr=0.010000 ...[m
[31m-==> Finished Epoch 362.[m
[31m-==> Start Training Epoch 363, lr=0.010000 ...[m
[31m-==> Finished Epoch 363.[m
[31m-==> Start Training Epoch 364, lr=0.010000 ...[m
[31m-==> Finished Epoch 364.[m
[31m-==> Start Training Epoch 365, lr=0.010000 ...[m
[31m-==> Finished Epoch 365.[m
[31m-==> Start Training Epoch 366, lr=0.010000 ...[m
[31m-==> Finished Epoch 366.[m
[31m-==> Start Training Epoch 367, lr=0.010000 ...[m
[31m-==> Finished Epoch 367.[m
[31m-==> Start Training Epoch 368, lr=0.010000 ...[m
[31m-==> Finished Epoch 368.[m
[31m-==> Start Training Epoch 369, lr=0.010000 ...[m
[31m-==> Finished Epoch 369.[m
[31m-==> Start Training Epoch 370, lr=0.010000 ...[m
[31m-==> Finished Epoch 370.[m
[31m-++> Evaluate at epoch 370 ...[m
[31m-PSNR = 22.358765 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 370 Finished.[m
[31m-[INFO] New best result: 0.00644010027948146 --> 0.006423985760193318[m
[31m-==> Start Training Epoch 371, lr=0.010000 ...[m
[31m-==> Finished Epoch 371.[m
[31m-==> Start Training Epoch 372, lr=0.010000 ...[m
[31m-==> Finished Epoch 372.[m
[31m-==> Start Training Epoch 373, lr=0.010000 ...[m
[31m-==> Finished Epoch 373.[m
[31m-==> Start Training Epoch 374, lr=0.010000 ...[m
[31m-==> Finished Epoch 374.[m
[31m-==> Start Training Epoch 375, lr=0.010000 ...[m
[31m-==> Finished Epoch 375.[m
[31m-==> Start Training Epoch 376, lr=0.010000 ...[m
[31m-==> Finished Epoch 376.[m
[31m-==> Start Training Epoch 377, lr=0.010000 ...[m
[31m-==> Finished Epoch 377.[m
[31m-==> Start Training Epoch 378, lr=0.010000 ...[m
[31m-==> Finished Epoch 378.[m
[31m-==> Start Training Epoch 379, lr=0.010000 ...[m
[31m-==> Finished Epoch 379.[m
[31m-==> Start Training Epoch 380, lr=0.010000 ...[m
[31m-==> Finished Epoch 380.[m
[31m-++> Evaluate at epoch 380 ...[m
[31m-PSNR = 22.416421 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 380 Finished.[m
[31m-[INFO] New best result: 0.006423985760193318 --> 0.006343394071639826[m
[31m-==> Start Training Epoch 381, lr=0.010000 ...[m
[31m-==> Finished Epoch 381.[m
[31m-==> Start Training Epoch 382, lr=0.010000 ...[m
[31m-==> Finished Epoch 382.[m
[31m-==> Start Training Epoch 383, lr=0.010000 ...[m
[31m-==> Finished Epoch 383.[m
[31m-==> Start Training Epoch 384, lr=0.010000 ...[m
[31m-==> Finished Epoch 384.[m
[31m-==> Start Training Epoch 385, lr=0.010000 ...[m
[31m-==> Finished Epoch 385.[m
[31m-==> Start Training Epoch 386, lr=0.010000 ...[m
[31m-==> Finished Epoch 386.[m
[31m-==> Start Training Epoch 387, lr=0.010000 ...[m
[31m-==> Finished Epoch 387.[m
[31m-==> Start Training Epoch 388, lr=0.010000 ...[m
[31m-==> Finished Epoch 388.[m
[31m-==> Start Training Epoch 389, lr=0.010000 ...[m
[31m-==> Finished Epoch 389.[m
[31m-==> Start Training Epoch 390, lr=0.010000 ...[m
[31m-==> Finished Epoch 390.[m
[31m-++> Evaluate at epoch 390 ...[m
[31m-PSNR = 22.445401 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 390 Finished.[m
[31m-[INFO] New best result: 0.006343394071639826 --> 0.006304266784961025[m
[31m-==> Start Training Epoch 391, lr=0.010000 ...[m
[31m-==> Finished Epoch 391.[m
[31m-==> Start Training Epoch 392, lr=0.010000 ...[m
[31m-==> Finished Epoch 392.[m
[31m-==> Start Training Epoch 393, lr=0.010000 ...[m
[31m-==> Finished Epoch 393.[m
[31m-==> Start Training Epoch 394, lr=0.010000 ...[m
[31m-==> Finished Epoch 394.[m
[31m-==> Start Training Epoch 395, lr=0.010000 ...[m
[31m-==> Finished Epoch 395.[m
[31m-==> Start Training Epoch 396, lr=0.010000 ...[m
[31m-==> Finished Epoch 396.[m
[31m-==> Start Training Epoch 397, lr=0.010000 ...[m
[31m-==> Finished Epoch 397.[m
[31m-==> Start Training Epoch 398, lr=0.010000 ...[m
[31m-==> Finished Epoch 398.[m
[31m-==> Start Training Epoch 399, lr=0.010000 ...[m
[31m-==> Finished Epoch 399.[m
[31m-==> Start Training Epoch 400, lr=0.010000 ...[m
[31m-==> Finished Epoch 400.[m
[31m-++> Evaluate at epoch 400 ...[m
[31m-PSNR = 22.478480 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 400 Finished.[m
[31m-[INFO] New best result: 0.006304266784961025 --> 0.006269399736387034[m
[31m-==> Start Training Epoch 401, lr=0.010000 ...[m
[31m-==> Finished Epoch 401.[m
[31m-==> Start Training Epoch 402, lr=0.010000 ...[m
[31m-==> Finished Epoch 402.[m
[31m-==> Start Training Epoch 403, lr=0.010000 ...[m
[31m-==> Finished Epoch 403.[m
[31m-==> Start Training Epoch 404, lr=0.010000 ...[m
[31m-==> Finished Epoch 404.[m
[31m-==> Start Training Epoch 405, lr=0.010000 ...[m
[31m-==> Finished Epoch 405.[m
[31m-==> Start Training Epoch 406, lr=0.010000 ...[m
[31m-==> Finished Epoch 406.[m
[31m-==> Start Training Epoch 407, lr=0.010000 ...[m
[31m-==> Finished Epoch 407.[m
[31m-==> Start Training Epoch 408, lr=0.010000 ...[m
[31m-==> Finished Epoch 408.[m
[31m-==> Start Training Epoch 409, lr=0.010000 ...[m
[31m-==> Finished Epoch 409.[m
[31m-==> Start Training Epoch 410, lr=0.010000 ...[m
[31m-==> Finished Epoch 410.[m
[31m-++> Evaluate at epoch 410 ...[m
[31m-PSNR = 22.486213 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 410 Finished.[m
[31m-[INFO] New best result: 0.006269399736387034 --> 0.006253587916338195[m
[31m-==> Start Training Epoch 411, lr=0.010000 ...[m
[31m-==> Finished Epoch 411.[m
[31m-==> Start Training Epoch 412, lr=0.010000 ...[m
[31m-==> Finished Epoch 412.[m
[31m-==> Start Training Epoch 413, lr=0.010000 ...[m
[31m-==> Finished Epoch 413.[m
[31m-==> Start Training Epoch 414, lr=0.010000 ...[m
[31m-==> Finished Epoch 414.[m
[31m-==> Start Training Epoch 415, lr=0.010000 ...[m
[31m-==> Finished Epoch 415.[m
[31m-==> Start Training Epoch 416, lr=0.010000 ...[m
[31m-==> Finished Epoch 416.[m
[31m-==> Start Training Epoch 417, lr=0.010000 ...[m
[31m-==> Finished Epoch 417.[m
[31m-==> Start Training Epoch 418, lr=0.010000 ...[m
[31m-==> Finished Epoch 418.[m
[31m-==> Start Training Epoch 419, lr=0.010000 ...[m
[31m-==> Finished Epoch 419.[m
[31m-==> Start Training Epoch 420, lr=0.010000 ...[m
[31m-==> Finished Epoch 420.[m
[31m-++> Evaluate at epoch 420 ...[m
[31m-PSNR = 22.495243 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 420 Finished.[m
[31m-[INFO] New best result: 0.006253587916338195 --> 0.006240103646026303[m
[31m-==> Start Training Epoch 421, lr=0.010000 ...[m
[31m-==> Finished Epoch 421.[m
[31m-==> Start Training Epoch 422, lr=0.010000 ...[m
[31m-==> Finished Epoch 422.[m
[31m-==> Start Training Epoch 423, lr=0.010000 ...[m
[31m-==> Finished Epoch 423.[m
[31m-==> Start Training Epoch 424, lr=0.010000 ...[m
[31m-==> Finished Epoch 424.[m
[31m-==> Start Training Epoch 425, lr=0.010000 ...[m
[31m-==> Finished Epoch 425.[m
[31m-==> Start Training Epoch 426, lr=0.010000 ...[m
[31m-==> Finished Epoch 426.[m
[31m-==> Start Training Epoch 427, lr=0.010000 ...[m
[31m-==> Finished Epoch 427.[m
[31m-==> Start Training Epoch 428, lr=0.010000 ...[m
[31m-==> Finished Epoch 428.[m
[31m-==> Start Training Epoch 429, lr=0.010000 ...[m
[31m-==> Finished Epoch 429.[m
[31m-==> Start Training Epoch 430, lr=0.010000 ...[m
[31m-==> Finished Epoch 430.[m
[31m-++> Evaluate at epoch 430 ...[m
[31m-PSNR = 22.504219 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 430 Finished.[m
[31m-[INFO] New best result: 0.006240103646026303 --> 0.006227381993085146[m
[31m-==> Start Training Epoch 431, lr=0.010000 ...[m
[31m-==> Finished Epoch 431.[m
[31m-==> Start Training Epoch 432, lr=0.010000 ...[m
[31m-==> Finished Epoch 432.[m
[31m-==> Start Training Epoch 433, lr=0.010000 ...[m
[31m-==> Finished Epoch 433.[m
[31m-==> Start Training Epoch 434, lr=0.010000 ...[m
[31m-==> Finished Epoch 434.[m
[31m-==> Start Training Epoch 435, lr=0.010000 ...[m
[31m-==> Finished Epoch 435.[m
[31m-==> Start Training Epoch 436, lr=0.010000 ...[m
[31m-==> Finished Epoch 436.[m
[31m-==> Start Training Epoch 437, lr=0.010000 ...[m
[31m-==> Finished Epoch 437.[m
[31m-==> Start Training Epoch 438, lr=0.010000 ...[m
[31m-==> Finished Epoch 438.[m
[31m-==> Start Training Epoch 439, lr=0.010000 ...[m
[31m-==> Finished Epoch 439.[m
[31m-==> Start Training Epoch 440, lr=0.010000 ...[m
[31m-==> Finished Epoch 440.[m
[31m-++> Evaluate at epoch 440 ...[m
[31m-PSNR = 22.514299 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 440 Finished.[m
[31m-[INFO] New best result: 0.006227381993085146 --> 0.006213534933825334[m
[31m-==> Start Training Epoch 441, lr=0.010000 ...[m
[31m-==> Finished Epoch 441.[m
[31m-==> Start Training Epoch 442, lr=0.010000 ...[m
[31m-==> Finished Epoch 442.[m
[31m-==> Start Training Epoch 443, lr=0.010000 ...[m
[31m-==> Finished Epoch 443.[m
[31m-==> Start Training Epoch 444, lr=0.010000 ...[m
[31m-==> Finished Epoch 444.[m
[31m-==> Start Training Epoch 445, lr=0.010000 ...[m
[31m-==> Finished Epoch 445.[m
[31m-==> Start Training Epoch 446, lr=0.010000 ...[m
[31m-==> Finished Epoch 446.[m
[31m-==> Start Training Epoch 447, lr=0.010000 ...[m
[31m-==> Finished Epoch 447.[m
[31m-==> Start Training Epoch 448, lr=0.010000 ...[m
[31m-==> Finished Epoch 448.[m
[31m-==> Start Training Epoch 449, lr=0.010000 ...[m
[31m-==> Finished Epoch 449.[m
[31m-==> Start Training Epoch 450, lr=0.010000 ...[m
[31m-==> Finished Epoch 450.[m
[31m-++> Evaluate at epoch 450 ...[m
[31m-PSNR = 22.518328 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 450 Finished.[m
[31m-[INFO] New best result: 0.006213534933825334 --> 0.006208335825552543[m
[31m-==> Start Training Epoch 451, lr=0.010000 ...[m
[31m-==> Finished Epoch 451.[m
[31m-==> Start Training Epoch 452, lr=0.010000 ...[m
[31m-==> Finished Epoch 452.[m
[31m-==> Start Training Epoch 453, lr=0.010000 ...[m
[31m-==> Finished Epoch 453.[m
[31m-==> Start Training Epoch 454, lr=0.010000 ...[m
[31m-==> Finished Epoch 454.[m
[31m-==> Start Training Epoch 455, lr=0.010000 ...[m
[31m-==> Finished Epoch 455.[m
[31m-==> Start Training Epoch 456, lr=0.010000 ...[m
[31m-==> Finished Epoch 456.[m
[31m-==> Start Training Epoch 457, lr=0.010000 ...[m
[31m-==> Finished Epoch 457.[m
[31m-==> Start Training Epoch 458, lr=0.010000 ...[m
[31m-==> Finished Epoch 458.[m
[31m-==> Start Training Epoch 459, lr=0.010000 ...[m
[31m-==> Finished Epoch 459.[m
[31m-==> Start Training Epoch 460, lr=0.010000 ...[m
[31m-==> Finished Epoch 460.[m
[31m-++> Evaluate at epoch 460 ...[m
[31m-PSNR = 22.519162 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 460 Finished.[m
[31m-==> Start Training Epoch 461, lr=0.010000 ...[m
[31m-==> Finished Epoch 461.[m
[31m-==> Start Training Epoch 462, lr=0.010000 ...[m
[31m-==> Finished Epoch 462.[m
[31m-==> Start Training Epoch 463, lr=0.010000 ...[m
[31m-==> Finished Epoch 463.[m
[31m-==> Start Training Epoch 464, lr=0.010000 ...[m
[31m-==> Finished Epoch 464.[m
[31m-==> Start Training Epoch 465, lr=0.010000 ...[m
[31m-==> Finished Epoch 465.[m
[31m-==> Start Training Epoch 466, lr=0.010000 ...[m
[31m-==> Finished Epoch 466.[m
[31m-==> Start Training Epoch 467, lr=0.010000 ...[m
[31m-==> Finished Epoch 467.[m
[31m-==> Start Training Epoch 468, lr=0.010000 ...[m
[31m-==> Finished Epoch 468.[m
[31m-==> Start Training Epoch 469, lr=0.010000 ...[m
[31m-==> Finished Epoch 469.[m
[31m-==> Start Training Epoch 470, lr=0.010000 ...[m
[31m-==> Finished Epoch 470.[m
[31m-++> Evaluate at epoch 470 ...[m
[31m-PSNR = 22.528884 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 470 Finished.[m
[31m-==> Start Training Epoch 471, lr=0.010000 ...[m
[31m-==> Finished Epoch 471.[m
[31m-==> Start Training Epoch 472, lr=0.010000 ...[m
[31m-==> Finished Epoch 472.[m
[31m-==> Start Training Epoch 473, lr=0.010000 ...[m
[31m-==> Finished Epoch 473.[m
[31m-==> Start Training Epoch 474, lr=0.010000 ...[m
[31m-==> Finished Epoch 474.[m
[31m-==> Start Training Epoch 475, lr=0.010000 ...[m
[31m-==> Finished Epoch 475.[m
[31m-==> Start Training Epoch 476, lr=0.010000 ...[m
[31m-==> Finished Epoch 476.[m
[31m-==> Start Training Epoch 477, lr=0.010000 ...[m
[31m-==> Finished Epoch 477.[m
[31m-==> Start Training Epoch 478, lr=0.010000 ...[m
[31m-==> Finished Epoch 478.[m
[31m-==> Start Training Epoch 479, lr=0.010000 ...[m
[31m-==> Finished Epoch 479.[m
[31m-==> Start Training Epoch 480, lr=0.010000 ...[m
[31m-==> Finished Epoch 480.[m
[31m-++> Evaluate at epoch 480 ...[m
[31m-PSNR = 22.390674 - SSIM = 0.000000 - LPIPS = 0.000000[m
[31m-++> Evaluate epoch 480 Finished.[m
[31m-==> Start Training Epoch 481, lr=0.010000 ...[m
[31m-==> Finished Epoch 481.[m
[31m-==> Start Training Epoch 482, lr=0.010000 ...[m
[31m-==> Finished Epoch 482.[m
[31m-==> Start Training Epoch 483, lr=0.010000 ...[m
[31m-==> Finished Epoch 483.[m
[31m-==> Start Training Epoch 484, lr=0.010000 ...[m
[31m-==> Finished Epoch 484.[m
[31m-==> Start Training Epoch 485, lr=0.010000 ...[m
[31m-==> Finished Epoch 485.[m
[31m-==> Start Training Epoch 486, lr=0.010000 ...[m
[31m-==> Finished Epoch 486.[m
[31m-==> Start Training Epoch 487, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-12-28 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0486.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 486, global step 5832[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 487, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-13-12 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0486.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 486, global step 5832[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 487, lr=0.010000 ...[m
[31m-[INFO] Trainer: ngp | 2022-08-16_00-14-04 | cuda | fp16 | Umbrella[m
[31m-[INFO] #parameters: 12953895[m
[31m-[INFO] Loading latest checkpoint ...[m
[31m-[INFO] Latest checkpoint is Umbrella/checkpoints/ngp_ep0486.pth[m
[31m-[INFO] loaded model.[m
[31m-[INFO] load at epoch 486, global step 5832[m
[31m-[WARN] Failed to load optimizer.[m
[31m-[INFO] loaded scheduler.[m
[31m-[INFO] loaded scaler.[m
[31m-==> Start Training Epoch 487, lr=0.010000 ...[m
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620083.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620083.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex c2ee586..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620083.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620133.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620133.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 0834d87..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660620133.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660621880.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660621880.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 964e6df..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660621880.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623149.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623149.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 4a4b1a6..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623149.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623194.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623194.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 96bb9ee..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623194.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623245.skhalid-MS-7A94 b/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623245.skhalid-MS-7A94[m
[1mdeleted file mode 100644[m
[1mindex 162ed61..0000000[m
Binary files a/Umbrella_21.92_0.6420_0.236/run/ngp/events.out.tfevents.1660623245.skhalid-MS-7A94 and /dev/null differ
[1mdiff --git a/dnerf/network.py b/dnerf/network.py[m
[1mindex 9902b13..145f44b 100644[m
[1m--- a/dnerf/network.py[m
[1m+++ b/dnerf/network.py[m
[36m@@ -146,7 +146,7 @@[m [mclass NeRFNetwork(NeRFRenderer):[m
         print("\nINITIALIZING DYNAMIC MODEL!!!\n")[m
         self.input_ch = 3[m
         self.D = 8  # FIXME: used to be 8![m
[31m-        self.W = 128  # FIXME: used to be 256![m
[32m+[m[32m        self.W = 64  # FIXME: used to be 256![m
         self.skips = [4][m
         self.pts_linears = nn.ModuleList([m
             [nn.Linear(self.input_ch, self.W)] + [nn.Linear(self.W, self.W) if i not in self.skips else nn.Linear(self.W + self.input_ch, self.W) for i in range(self.D-1)])[m
[36m@@ -462,6 +462,8 @@[m [mclass NeRFNetwork(NeRFRenderer):[m
             params = [[m
                 {'params': self.encoder.parameters(), 'lr': lr},[m
                 {'params': self.encoder_dir.parameters(), 'lr': lr},[m
[32m+[m[32m                {'params': self.encoder_deform.parameters(), 'lr': lr},[m
[32m+[m[32m                {'params': self.encoder_time.parameters(), 'lr': lr},[m
                 {'params': self.sigma_s_net.parameters(), 'lr': lr_net},[m
                 {'params': self.color_s_net.parameters(), 'lr': lr_net},[m
             ][m
[1mdiff --git a/dnerf/provider.py b/dnerf/provider.py[m
[1mindex e1093af..dd74e02 100644[m
[1m--- a/dnerf/provider.py[m
[1m+++ b/dnerf/provider.py[m
[36m@@ -119,7 +119,7 @@[m [mclass NeRFDataset:[m
         # self.masks = self.masks_val if self.training else self.masks[m
 [m
         self.rand_pose = opt.rand_pose[m
[31m-        self.MAX_STATIC_ITERS = eval(opt.max_static_iters)[m
[32m+[m[32m        self.MAX_STATIC_ITERS = opt.max_static_iters[m
         self.STATIC_ITERS = 0[m
 [m
         # auto-detect transforms.json and split mode.[m
[1mdiff --git a/dnerf/renderer.py b/dnerf/renderer.py[m
[1mindex bd13fcb..50c36fc 100644[m
[1m--- a/dnerf/renderer.py[m
[1m+++ b/dnerf/renderer.py[m
[36m@@ -323,36 +323,29 @@[m [mclass NeRFRenderer(nn.Module):[m
             inds_d = kwargs['inds_d'][m
             N_static = len(inds_s) if type(inds_s) != int else 0[m
             N_dynamic = len(inds_d) if type(inds_d) != int else 0[m
[31m-[m
[31m-            rays_o_s = rays_o[:N_static, :][m
[31m-            rays_o_d = rays_o[N_static:, :][m
[31m-            rays_d_s = rays_d[:N_static, :][m
[31m-            rays_d_d = rays_d[N_static:, :][m
[31m-            prefix_s = (rays_o[:N_static, :].shape[0])[m
[31m-            prefix_d = (rays_o[N_static:, :].shape[0])[m
         else:[m
             if (DEBUG):[m
                 print()[m
                 print(kwargs['inds_s'].shape)[m
                 print(kwargs['inds_d'].shape)[m
                 print()[m
[32m+[m[32m            # inds_s = kwargs['inds_s'][m
[32m+[m[32m            # inds_d = kwargs['inds_d'][m
[32m+[m
             rend_s = kwargs['inds_s'][m
             rend_d = kwargs['inds_d'][m
[31m-            # rend_s = [v for v in range(129600)][m
[31m-            # rend_d = [v for v in range(129600)][m
[31m-            inds_s = [v for v in range(480*270)][m
[31m-            inds_d = [v for v in range(480*270)][m
[32m+[m[32m            inds_s = [v for v in range(129600)][m
[32m+[m[32m            inds_d = [v for v in range(129600)][m
 [m
             N_static = len(inds_s) if type(inds_s) != int else 0[m
             N_dynamic = len(inds_d) if type(inds_d) != int else 0[m
 [m
[31m-            # FIXME[m
[31m-            rays_o_s = rays_o[m
[31m-            rays_o_d = rays_o[m
[31m-            rays_d_s = rays_d[m
[31m-            rays_d_d = rays_d[m
[31m-            prefix_s = (rays_o.shape[0])[m
[31m-            prefix_d = (rays_o.shape[0])[m
[32m+[m[32m        rays_o_s = rays_o[:N_static, :][m
[32m+[m[32m        rays_o_d = rays_o[-N_dynamic:, :][m
[32m+[m[32m        rays_d_s = rays_d[:N_static, :][m
[32m+[m[32m        rays_d_d = rays_d[-N_dynamic:, :][m
[32m+[m[32m        prefix_s = (rays_o[:N_static, :].shape[0])[m
[32m+[m[32m        prefix_d = (rays_o[-N_dynamic:, :].shape[0])[m
 [m
         if (DEBUG):[m
             print("\nN_static: {}".format(N_static))[m
[36m@@ -800,40 +793,18 @@[m [mclass NeRFRenderer(nn.Module):[m
                     N, 3, dtype=dtype, device=device)[m
                 # print("weights_sum_s.shape: {}".format(weights_sum_s.shape))[m
                 # print("weights_sum_d.shape: {}".format(weights_sum_d.shape))[m
[31m-[m
[31m-                #image_s_tmp[rend_s, :] = image_s[rend_s, :][m
[31m-                #image_d_tmp[rend_d, :] = image_d[rend_d, :][m
[31m-[m
[31m-                # image_s_tmp[rend_s, :] = ([m
[31m-                #     weights_sum_s).unsqueeze(-1)[rend_s, :] * bg_color[m
[31m-                # image_d_tmp[rend_d, :] = ([m
[31m-                #     weights_sum_d).unsqueeze(-1)[rend_d, :] * bg_color[m
                 image_s_tmp[rend_s, :] = image_s[rend_s, :] + \[m
                     (1 - weights_sum_s).unsqueeze(-1)[rend_s, :] * bg_color[m
                 image_d_tmp[rend_d, :] = image_d[rend_d, :] + \[m
                     (1 - weights_sum_d).unsqueeze(-1)[rend_d, :] * bg_color[m
[31m-[m
[31m-                # print("image_s_tmp.min: {}".format(image_s_tmp.min()))[m
[31m-                # print("image_s_tmp.max: {}".format(image_s_tmp.max()))[m
[31m-                # print("image_s.min: {}".format(image_s.min()))[m
[31m-                # print("image_s.max: {}".format(image_s.max()))[m
[31m-                # print("weights_sum_s.min: {}".format(weights_sum_s.min()))[m
[31m-                # print("weights_sum_s.max: {}".format(weights_sum_s.max()))[m
[31m-                # print("image_d_tmp.min: {}".format(image_d_tmp.min()))[m
[31m-                # print("image_d_tmp.max: {}".format(image_d_tmp.max()))[m
[31m-                # print("image_d.min: {}".format(image_d.min()))[m
[31m-                # print("image_d.max: {}".format(image_d.max()))[m
[31m-                # print("weights_sum_d.min: {}".format(weights_sum_d.min()))[m
[31m-                # print("weights_sum_d.max: {}".format(weights_sum_d.max()))[m
[31m-                # print("bg_color: {}".format(bg_color))[m
                 # print("image_s_tmp.shape: {}".format(image_s_tmp.shape))[m
                 # print("image_d.shape: {}".format(image_d.shape))[m
                 # print("image_d_tmp.shape: {}".format(image_d_tmp.shape))[m
                 # image = image_d + (1 - weights_sum_d).unsqueeze(-1) * bg_color[m
                 image = image_s_tmp + image_d_tmp[m
                 # FIXME: nears and fars are logically incorrect[m
[31m-                # depth = torch.clamp(depth_d - nears_d,[m
[31m-                #                     min=0) / (fars_d - nears_d)[m
[32m+[m[32m                depth = torch.clamp(depth_d - nears_d,[m
[32m+[m[32m                                    min=0) / (fars_d - nears_d)[m
                 image = image.view(N, 3)[m
                 depth = image[:, 0]  # FIXME[m
                 # depth = depth.view(prefix_s + prefix_d)[m
[1mdiff --git a/dnerf/utils.py b/dnerf/utils.py[m
[1mindex c2b8b4c..1936245 100644[m
[1m--- a/dnerf/utils.py[m
[1m+++ b/dnerf/utils.py[m
[36m@@ -160,7 +160,6 @@[m [mclass Trainer(_Trainer):[m
                 'deform_loss_lambda': 1.0[m
             }[m
 [m
[31m-            # TODO: Combined loss[m
             # img_loss = img2mse(ret['rgb_map_full'], gt_rgb)[m
             # psnr = mse2psnr(img_loss)[m
             # loss_dict['psnr'] = psnr[m
[36m@@ -168,8 +167,8 @@[m [mclass Trainer(_Trainer):[m
             # loss += args['full_loss_lambda'] * loss_dict['img_loss'][m
 [m
             # Deformation Loss[m
[31m-            # loss_dict['deform_loss'] = ret['deform'].abs().mean()[m
[31m-            # loss += args['deform_loss_lambda'] * loss_dict['deform_loss'][m
[32m+[m[32m            loss_dict['deform_loss'] = ret['deform'].abs().mean()[m
[32m+[m[32m            loss += args['deform_loss_lambda'] * loss_dict['deform_loss'][m
 [m
             # Compute MSE loss between rgb_s and true RGB.[m
             if ("rgb_map_s" in ret):[m
[36m@@ -250,24 +249,24 @@[m [mclass Trainer(_Trainer):[m
             #         loss += args['flow_loss_lambda'] * \[m
             #             Temp * loss_dict['flow_b_loss'][m
 [m
[31m-            # # Slow scene flow. The forward and backward sceneflow should be small.[m
[31m-            # if ('sceneflow_f' in ret and 'sceneflow_b' in ret):[m
[31m-            #     slow_loss = L1(ret['sceneflow_b']) + \[m
[31m-            #         L1(ret['sceneflow_f'])[m
[31m-            #     loss_dict['slow_loss'] = slow_loss[m
[31m-            #     loss += args['slow_loss_lambda'] * loss_dict['slow_loss'][m
[32m+[m[32m            # Slow scene flow. The forward and backward sceneflow should be small.[m
[32m+[m[32m            if ('sceneflow_f' in ret and 'sceneflow_b' in ret):[m
[32m+[m[32m                slow_loss = L1(ret['sceneflow_b']) + \[m
[32m+[m[32m                    L1(ret['sceneflow_f'])[m
[32m+[m[32m                loss_dict['slow_loss'] = slow_loss[m
[32m+[m[32m                loss += args['slow_loss_lambda'] * loss_dict['slow_loss'][m
[32m+[m
[32m+[m[32m            # Smooth scene flow. The summation of the forward and backward sceneflow should be small.[m
[32m+[m[32m            if ('raw_pts' in ret and 'raw_pts_b' in ret and 'raw_pts_f' in ret):[m
[32m+[m[32m                smooth_loss = compute_sf_smooth_loss(ret['raw_pts'],[m
[32m+[m[32m                                                     ret['raw_pts_f'],[m
[32m+[m[32m                                                     ret['raw_pts_b'],[m
[32m+[m[32m                                                     H, W, focal)[m
[32m+[m[32m                loss_dict['smooth_loss'] = smooth_loss[m
[32m+[m[32m                loss += args['smooth_loss_lambda'] * loss_dict['smooth_loss'][m
 [m
[31m-            # # Smooth scene flow. The summation of the forward and backward sceneflow should be small.[m
[31m-            # if ('raw_pts' in ret and 'raw_pts_b' in ret and 'raw_pts_f' in ret):[m
[31m-            #     smooth_loss = compute_sf_smooth_loss(ret['raw_pts'],[m
[31m-            #                                          ret['raw_pts_f'],[m
[31m-            #                                          ret['raw_pts_b'],[m
[31m-            #                                          H, W, focal)[m
[31m-            #     loss_dict['smooth_loss'] = smooth_loss[m
[31m-            #     loss += args['smooth_loss_lambda'] * loss_dict['smooth_loss'][m
[31m-[m
[31m-            # # Spatial smooth scene flow. (loss adapted from NSFF)[m
             # if ('raw_pts' in ret and 'raw_pts_b' in ret and 'raw_pts_f' in ret):[m
[32m+[m[32m            #     # Spatial smooth scene flow. (loss adapted from NSFF)[m
             #     sp_smooth_loss = compute_sf_smooth_s_loss(ret['raw_pts'], ret['raw_pts_f'], H, W, focal) \[m
             #         + compute_sf_smooth_s_loss(ret['raw_pts'],[m
             #                                    ret['raw_pts_b'], H, W, focal)[m
[36m@@ -275,7 +274,6 @@[m [mclass Trainer(_Trainer):[m
             #     loss += args['smooth_loss_lambda'] * \[m
             #         loss_dict['sp_smooth_loss'][m
 [m
[31m-            # FIXME:This breaks everything :([m
             # # Consistency loss.[m
             # if ('sceneflow_f' in ret and 'sceneflow_b' in ret and 'sceneflow_f_b' in ret):[m
             #     consistency_loss = L1(ret['sceneflow_f'].cuda() + ret['sceneflow_f_b'].cuda()) + \[m
[36m@@ -303,14 +301,14 @@[m [mclass Trainer(_Trainer):[m
             #     loss_dict['sparse_loss'] = sparse_loss[m
             #     loss += args['sparse_loss_lambda'] * loss_dict['sparse_loss'][m
 [m
[31m-            # # Depth constraint[m
[31m-            # # Depth in NDC space equals to negative disparity in Euclidean space.[m
[31m-            # if ('depth_map_d' in ret):[m
[31m-            #     depth_loss = compute_depth_loss([m
[31m-            #         ret['depth_map_d'], -batch_invdepth)[m
[31m-            #     loss_dict['depth_loss'] = depth_loss[m
[31m-            #     loss += args['depth_loss_lambda'] * \[m
[31m-            #         Temp * loss_dict['depth_loss'][m
[32m+[m[32m            # Depth constraint[m
[32m+[m[32m            # Depth in NDC space equals to negative disparity in Euclidean space.[m
[32m+[m[32m            if ('depth_map_d' in ret):[m
[32m+[m[32m                depth_loss = compute_depth_loss([m
[32m+[m[32m                    ret['depth_map_d'], -batch_invdepth)[m
[32m+[m[32m                loss_dict['depth_loss'] = depth_loss[m
[32m+[m[32m                loss += args['depth_loss_lambda'] * \[m
[32m+[m[32m                    Temp * loss_dict['depth_loss'][m
 [m
             # FIXME: Order loss[m
             # order_loss = torch.mean(torch.square(ret['depth_map_d'][batch_mask[0].type(torch.bool)] -[m
[36m@@ -330,19 +328,19 @@[m [mclass Trainer(_Trainer):[m
             # loss_dict['sf_smooth_loss'] = sf_smooth_loss[m
             # loss += args['smooth_loss_lambda'] * loss_dict['sf_smooth_loss'][m
 [m
[31m-            # if chain_5frames:[m
[31m-            #     if ('rgb_map_d_b_b' in ret and 'rgb_map_d_f_f' in ret):[m
[31m-            #         img_d_b_b_loss = img2mse([m
[31m-            #             ret['rgb_map_d_b_b'], gt_rgb[:, :ret['rgb_map_d_b_b'].shape[0], :])[m
[31m-            #         loss_dict['img_d_b_b_loss'] = img_d_b_b_loss[m
[31m-            #         loss += args['dynamic_loss_lambda'] * \[m
[31m-            #             loss_dict['img_d_b_b_loss'][m
[31m-[m
[31m-            #         img_d_f_f_loss = img2mse([m
[31m-            #             ret['rgb_map_d_f_f'], gt_rgb[:, :ret['rgb_map_d_f_f'].shape[0], :])[m
[31m-            #         loss_dict['img_d_f_f_loss'] = img_d_f_f_loss[m
[31m-            #         loss += args['dynamic_loss_lambda'] * \[m
[31m-            #             loss_dict['img_d_f_f_loss'][m
[32m+[m[32m            if chain_5frames:[m
[32m+[m[32m                if ('rgb_map_d_b_b' in ret and 'rgb_map_d_f_f' in ret):[m
[32m+[m[32m                    img_d_b_b_loss = img2mse([m
[32m+[m[32m                        ret['rgb_map_d_b_b'], gt_rgb[:, :ret['rgb_map_d_b_b'].shape[0], :])[m
[32m+[m[32m                    loss_dict['img_d_b_b_loss'] = img_d_b_b_loss[m
[32m+[m[32m                    loss += args['dynamic_loss_lambda'] * \[m
[32m+[m[32m                        loss_dict['img_d_b_b_loss'][m
[32m+[m
[32m+[m[32m                    img_d_f_f_loss = img2mse([m
[32m+[m[32m                        ret['rgb_map_d_f_f'], gt_rgb[:, :ret['rgb_map_d_f_f'].shape[0], :])[m
[32m+[m[32m                    loss_dict['img_d_f_f_loss'] = img_d_f_f_loss[m
[32m+[m[32m                    loss += args['dynamic_loss_lambda'] * \[m
[32m+[m[32m                        loss_dict['img_d_f_f_loss'][m
 [m
             # print("\n{}\n".format(loss_dict))[m
 [m
[1mdiff --git a/main_dnerf.py b/main_dnerf.py[m
[1mindex 117744f..cdacc9c 100644[m
[1m--- a/main_dnerf.py[m
[1m+++ b/main_dnerf.py[m
[36m@@ -21,7 +21,7 @@[m [mif __name__ == '__main__':[m
     parser.add_argument('--seed', type=int, default=0)[m
 [m
     # training options[m
[31m-    parser.add_argument('--iters', type=int, default=24000,[m
[32m+[m[32m    parser.add_argument('--iters', type=int, default=100000,[m
                         help="training iters")[m
     parser.add_argument('--lr', type=float, default=1e-2,  # 1e-2[m
                         help="initial learning rate")[m
[36m@@ -29,16 +29,14 @@[m [mif __name__ == '__main__':[m
                         help="initial learning rate")[m
     parser.add_argument('--ckpt', type=str, default='latest')[m
 [m
[31m-    # =================================================================================[m
     parser.add_argument('--num_rays', type=int, default=4096,[m
                         help="num rays sampled per image for each training step")[m
     parser.add_argument('--cuda_ray', action='store_true',[m
                         help="use CUDA raymarching instead of pytorch")[m
     parser.add_argument('--max_steps', type=int, default=128,  # sk_debug: used to be 1024[m
                         help="max num steps sampled per ray (only valid when using --cuda_ray)")[m
[31m-    parser.add_argument('--max_static_iters', type=str, default="[(1,100), (200,300)]",  # 2400 iters[m
[32m+[m[32m    parser.add_argument('--max_static_iters', type=int, default=0,  # 1000 iters[m
                         help="iters to train the static model for - to be followed by dynamic model")[m
[31m-    # =================================================================================[m
 [m
     parser.add_argument('--update_extra_interval', type=int, default=100,[m
                         help="iter interval to update extra status (only valid when using --cuda_ray)")[m
[1mdiff --git a/nerf/utils.py b/nerf/utils.py[m
[1mindex edb924c..aaccfd4 100644[m
[1m--- a/nerf/utils.py[m
[1m+++ b/nerf/utils.py[m
[36m@@ -95,45 +95,39 @@[m [mdef get_rays(poses, intrinsics, H, W, masks, N=-1, error_map=None, static_iters=[m
                 mask = masks[e:masks.shape[0]-e, 0].to(device)[m
 [m
                 coords_s = torch.where(mask < 0.5)[0][m
[31m-                coords_d = torch.where(mask > 0.5)[0][m
[32m+[m[32m                coords_d = torch.where(mask >= 0.5)[0][m
                 # print("\ncoords_s: {}".format(coords_s))[m
                 # print("coords_d: {}".format(coords_d))[m
 [m
                 # inds = torch.cat([coords_s, coords_d], 0)[m
[31m-                cond = np.array([static_iters >= u and static_iters <=[m
[31m-                                 v for (u, v) in max_static_iters]).sum()[m
[31m-                if (cond):[m
[31m-                    print("\n\n=======================================")[m
[31m-                    print([m
[31m-                        "STATIC MODEL ACTIVATED!!! - (get_rays) - iter: {}".format(static_iters))[m
[31m-                    print("=======================================\n\n")[m
[31m-                    # print([m
[31m-                    #     "\n\n\static_iter: {}/{}\n\n\n".format(static_iters, max_static_iters))[m
[32m+[m[32m                if (static_iters > max_static_iters):[m
[32m+[m[32m                    # print("\n\n=======================================")[m
[32m+[m[32m                    # print("DYNAMIC MODEL ACTIVATED!!! - (get_rays)")[m
[32m+[m[32m                    # print("=======================================\n\n")[m
                     inds_s = torch.randint([m
[31m-                        0, coords_s.shape[-1]-1, size=[int(N)], device=device)  # may duplicate[m
[32m+[m[32m                        0, coords_s.shape[-1]-1, size=[int(0)], device=device)  # may duplicate[m
                     inds_d = torch.randint([m
[31m-                        0, coords_s.shape[-1]-1, size=[0], device=device)  # may duplicate[m
[32m+[m[32m                        0, coords_d.shape[-1]-1, size=[int(N)], device=device)  # may duplicate[m
 [m
                     coords_s = coords_s[inds_s][m
                     coords_d = coords_d[inds_d][m
[31m-                    inds = torch.cat([coords_s], 0)[m
[31m-                    results['inds_s'] = coords_s[m
[32m+[m[32m                    inds = torch.cat([coords_d], 0)[m
[32m+[m[32m                    results['inds_s'] = 0[m
                     results['inds_d'] = coords_d[m
                 else:[m
[31m-                    print("\n\n=======================================")[m
[31m-                    print([m
[31m-                        "DYNAMIC MODEL ACTIVATED!!! - (get_rays) - iter: {}".format(static_iters))[m
[31m-                    print("=======================================\n\n")[m
[32m+[m[32m                    # print([m
[32m+[m[32m                    #     "\n\n\static_iter: {}/{}\n\n\n".format(static_iters, max_static_iters))[m
                     inds_s = torch.randint([m
[31m-                        0, coords_s.shape[-1]-1, size=[0], device=device)  # may duplicate[m
[32m+[m[32m                        0, coords_s.shape[-1]-1, size=[int(N)], device=device)  # may duplicate[m
                     inds_d = torch.randint([m
[31m-                        0, coords_d.shape[-1]-1, size=[int(N)], device=device)  # may duplicate[m
[32m+[m[32m                        0, coords_d.shape[-1]-1, size=[int(0)], device=device)  # may duplicate[m
 [m
                     coords_s = coords_s[inds_s][m
                     coords_d = coords_d[inds_d][m
[31m-                    inds = torch.cat([coords_d], 0)[m
[32m+[m[32m                    inds = torch.cat([coords_s], 0)[m
                     results['inds_s'] = coords_s[m
[31m-                    results['inds_d'] = coords_d[m
[32m+[m[32m                    results['inds_d'] = 0[m
[32m+[m
                 # print("\ncoords_s: {}".format(coords_s))[m
                 # print("coords_d: {}".format(coords_d))[m
 [m
[36m@@ -175,7 +169,7 @@[m [mdef get_rays(poses, intrinsics, H, W, masks, N=-1, error_map=None, static_iters=[m
             mask = masks[:masks.shape[0], 0].to(device)[m
 [m
             coords_s = torch.where(mask < 0.5)[0][m
[31m-            coords_d = torch.where(mask > 0.5)[0][m
[32m+[m[32m            coords_d = torch.where(mask >= 0.5)[0][m
 [m
             # inds_s = torch.randint([m
             #     0, coords_s.shape[-1]-1, size=[int(N)], device=device)  # may duplicate[m
[36m@@ -896,19 +890,8 @@[m [mclass Trainer(object):[m
 [m
         self.local_step = 0[m
 [m
[31m-        print("self.global_step: {}".format(self.global_step))[m
[31m-        print(self.opt.max_static_iters)[m
[31m-        print(type(self.opt.max_static_iters))[m
[31m-        cond = np.array([self.global_step >= u and self.global_step <=[m
[31m-                         v for (u, v) in eval(self.opt.max_static_iters)]).sum()[m
[31m-        # if ((self.global_step >= self.opt.max_static_iters) and self.opt_state != "dynamic"):[m
[31m-        if (cond and self.opt_state != "static"):[m
[31m-            print("\n\n========================================")[m
[31m-            print("STATIC MODEL ACTIVATED!!! - (optimizer)")[m
[31m-            print("========================================\n\n")[m
[31m-            self.opt_state = "static"[m
[31m-            self.optimizer = self.optimizer_func(self.model, self.opt_state)[m
[31m-        elif (cond and self.opt_state != "dynamic"):[m
[32m+[m[32m        # print("self.global_step: {}".format(self.global_step))[m
[32m+[m[32m        if ((self.global_step >= self.opt.max_static_iters) and self.opt_state != "dynamic"):[m
             print("\n\n========================================")[m
             print("DYNAMIC MODEL ACTIVATED!!! - (optimizer)")[m
             print("========================================\n\n")[m
